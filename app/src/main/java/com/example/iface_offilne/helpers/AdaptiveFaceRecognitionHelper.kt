package com.example.iface_offilne.helpers

import android.content.Context
import android.graphics.Bitmap
import android.graphics.Rect
import android.util.Log
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import com.google.mlkit.vision.face.FaceLandmark
import com.google.mlkit.vision.face.Face
import org.tensorflow.lite.Interpreter
import java.nio.ByteBuffer
import java.nio.ByteOrder
import kotlin.math.abs
import kotlin.math.sqrt
import kotlinx.coroutines.tasks.await
import com.example.iface_offilne.helpers.PerformanceLevel


/**
 * üöÄ HELPER ADAPTATIVO PARA RECONHECIMENTO FACIAL
 * 
 * Sistema inteligente que ajusta automaticamente os par√¢metros
 * de reconhecimento facial baseado nas capacidades do dispositivo
 * 
 * ‚úÖ Funciona em dispositivos de baixo desempenho
 * ‚úÖ Mant√©m precis√£o em dispositivos potentes
 * ‚úÖ Otimiza√ß√£o autom√°tica de performance
 */
class AdaptiveFaceRecognitionHelper(private val context: Context) {
    
    companion object {
        private const val TAG = "AdaptiveFaceRecognition"
    }
    
    private val deviceCapabilityHelper = DeviceCapabilityHelper(context)
    private val adaptiveConfig = deviceCapabilityHelper.getAdaptiveFaceRecognitionConfig()
    private val deviceInfo = deviceCapabilityHelper.getDeviceInfo()
    
    private val faceDetector = FaceDetection.getClient(
        FaceDetectorOptions.Builder()
            .setPerformanceMode(
                when (adaptiveConfig.imageQuality) {
                    DeviceCapabilityHelper.ImageQuality.LOW -> FaceDetectorOptions.PERFORMANCE_MODE_FAST
                    DeviceCapabilityHelper.ImageQuality.MEDIUM -> FaceDetectorOptions.PERFORMANCE_MODE_FAST
                    DeviceCapabilityHelper.ImageQuality.HIGH -> FaceDetectorOptions.PERFORMANCE_MODE_ACCURATE
                }
            )
            .setLandmarkMode(
                when (adaptiveConfig.imageQuality) {
                    DeviceCapabilityHelper.ImageQuality.LOW -> FaceDetectorOptions.LANDMARK_MODE_NONE
                    DeviceCapabilityHelper.ImageQuality.MEDIUM -> FaceDetectorOptions.LANDMARK_MODE_ALL
                    DeviceCapabilityHelper.ImageQuality.HIGH -> FaceDetectorOptions.LANDMARK_MODE_ALL
                }
            )
            .setClassificationMode(
                when (adaptiveConfig.imageQuality) {
                    DeviceCapabilityHelper.ImageQuality.LOW -> FaceDetectorOptions.CLASSIFICATION_MODE_NONE
                    DeviceCapabilityHelper.ImageQuality.MEDIUM -> FaceDetectorOptions.CLASSIFICATION_MODE_ALL
                    DeviceCapabilityHelper.ImageQuality.HIGH -> FaceDetectorOptions.CLASSIFICATION_MODE_ALL
                }
            )
            .setMinFaceSize(
                when (adaptiveConfig.imageQuality) {
                    DeviceCapabilityHelper.ImageQuality.LOW -> 0.05f
                    DeviceCapabilityHelper.ImageQuality.MEDIUM -> 0.1f
                    DeviceCapabilityHelper.ImageQuality.HIGH -> 0.15f
                }
            )
            .build()
    )
    
    private var interpreter: Interpreter? = null
    private var modelLoaded = false
    
    init {
        Log.d(TAG, "üöÄ === INICIANDO HELPER ADAPTATIVO ===")
        Log.d(TAG, "üìä Dispositivo: ${deviceInfo.performanceLevel} (Score: ${String.format("%.1f", deviceInfo.deviceScore)}/100)")
        Log.d(TAG, "üíæ Mem√≥ria: ${String.format("%.1f", deviceInfo.memoryInfo.totalGB)}GB")
        Log.d(TAG, "üñ•Ô∏è CPU: ${deviceInfo.cpuInfo.cores} cores")
        Log.d(TAG, "ü§ñ Android: ${deviceInfo.androidRelease} (API ${deviceInfo.androidVersion})")
        
        loadTensorFlowModel()
    }
    
    /**
     * üîç RECONHECIMENTO FACIAL ADAPTATIVO
     * Ajusta automaticamente a qualidade baseado no dispositivo
     */
    suspend fun recognizeFaceAdaptive(faceBitmap: Bitmap): FaceRecognitionResult {
        return try {
            Log.d(TAG, "üîç === RECONHECIMENTO FACIAL ADAPTATIVO ===")
            
            // ‚úÖ OBTER CONFIGURA√á√ÉO ADAPTATIVA
            val config = deviceCapabilityHelper.getAdaptiveFaceRecognitionConfig()
            Log.d(TAG, "üéõÔ∏è Configura√ß√£o: ${deviceCapabilityHelper.getDeviceInfo()?.performanceLevel}")
            Log.d(TAG, "üìä Thresholds: Similaridade>=${config.minSimilarityThreshold}, Dist√¢ncia<=${config.maxEuclideanDistance}, Confian√ßa>=${config.requiredConfidence}")
            
            // ‚úÖ VALIDAR BITMAP DE ENTRADA
            if (faceBitmap.isRecycled || faceBitmap.width <= 0 || faceBitmap.height <= 0) {
                Log.e(TAG, "‚ùå Bitmap inv√°lido: reciclado=${faceBitmap.isRecycled}, dimens√µes=${faceBitmap.width}x${faceBitmap.height}")
                return FaceRecognitionResult.Failure("Bitmap inv√°lido")
            }
            
            Log.d(TAG, "üì∏ Processando face: ${faceBitmap.width}x${faceBitmap.height}")
            
            // ‚úÖ CALCULAR QUALIDADE DA IMAGEM
            val quality = calculateImageQuality(faceBitmap)
            Log.d(TAG, "üìä Qualidade: Brilho=${String.format("%.3f", quality.brightness)}, Contraste=${String.format("%.3f", quality.contrast)}")
            
            // ‚úÖ ACEITAR FACE J√Å DETECTADA - N√ÉO TENTAR DETECTAR NOVAMENTE
            Log.d(TAG, "‚úÖ Face j√° detectada e recortada - processando diretamente")
            
            // ‚úÖ GERAR EMBEDDING
            val embedding = try {
                generateEmbedding(faceBitmap)
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro ao gerar embedding: ${e.message}")
                return FaceRecognitionResult.Failure("Erro ao gerar embedding: ${e.message}")
            }
            
            if (embedding.isEmpty()) {
                Log.e(TAG, "‚ùå Embedding vazio")
                return FaceRecognitionResult.Failure("Embedding vazio")
            }
            
            Log.d(TAG, "‚úÖ Embedding gerado: ${embedding.size} dimens√µes")
            
            // ‚úÖ EXECUTAR RECONHECIMENTO
            val recognitionResult = performAdaptiveRecognition(embedding)
            
            when (recognitionResult) {
                is FaceRecognitionResult.Success -> {
                    Log.d(TAG, "‚úÖ RECONHECIMENTO BEM-SUCEDIDO!")
                    Log.d(TAG, "üë§ Funcion√°rio: ${recognitionResult.funcionario.nome}")
                    Log.d(TAG, "üìä M√©tricas: Similaridade=${String.format("%.3f", recognitionResult.similarity)}, Dist√¢ncia=${String.format("%.3f", recognitionResult.euclideanDistance)}, Confian√ßa=${String.format("%.3f", recognitionResult.confidence)}")
                }
                is FaceRecognitionResult.Failure -> {
                    Log.w(TAG, "‚ùå RECONHECIMENTO FALHOU: ${recognitionResult.reason}")
                }
            }
            
            recognitionResult
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro cr√≠tico no reconhecimento adaptativo: ${e.message}")
            e.printStackTrace()
            FaceRecognitionResult.Failure("Erro interno: ${e.message}")
        }
    }
    
    /**
     * üéØ RECONHECIMENTO ADAPTATIVO COM CONFIGURA√á√ïES DIN√ÇMICAS
     */
    private suspend fun performAdaptiveRecognition(embedding: FloatArray): FaceRecognitionResult {
        return try {
            Log.d(TAG, "üîç === INICIANDO RECONHECIMENTO ADAPTATIVO ===")
            
            // ‚úÖ Carregar dados do banco
            val db = com.example.iface_offilne.data.AppDatabase.getInstance(context)
            val faceDao = db.faceDao()
            val funcionarioDao = db.usuariosDao()
            
            val faces = faceDao.getAllFaces()
            val funcionarios = funcionarioDao.getUsuario()
            
            Log.d(TAG, "üìä Faces cadastradas no banco: ${faces.size}")
            Log.d(TAG, "üë• Funcion√°rios cadastrados: ${funcionarios.size}")
            
            if (faces.isEmpty()) {
                Log.e(TAG, "‚ùå NENHUMA FACE CADASTRADA NO BANCO!")
                return FaceRecognitionResult.Failure("Nenhuma face cadastrada no sistema")
            }
            
            if (funcionarios.isEmpty()) {
                Log.e(TAG, "‚ùå NENHUM FUNCION√ÅRIO CADASTRADO NO BANCO!")
                return FaceRecognitionResult.Failure("Nenhum funcion√°rio cadastrado no sistema")
            }
            
            Log.d(TAG, "üìê Embedding de entrada: ${embedding.size} dimens√µes")
            Log.d(TAG, "üéØ Thresholds: Similaridade‚â•${adaptiveConfig.minSimilarityThreshold}, Dist√¢ncia‚â§${adaptiveConfig.maxEuclideanDistance}, Confian√ßa‚â•${adaptiveConfig.requiredConfidence}")
            
            // ‚úÖ VARI√ÅVEIS PARA MELHOR MATCH
            var bestMatch: com.example.iface_offilne.data.FuncionariosEntity? = null
            var bestSimilarity = 0f
            var bestEuclideanDistance = Float.MAX_VALUE
            var bestConfidence = 0f
            var allResults = mutableListOf<String>()
            
            // ‚úÖ COMPARA√á√ÉO ADAPTATIVA
            for ((index, face) in faces.withIndex()) {
                try {
                    Log.d(TAG, "üîÑ Processando face ${index + 1}/${faces.size}: ID=${face.funcionarioId}")
                    
                    val storedEmbedding = parseEmbedding(face.embedding)
                    if (storedEmbedding == null) {
                        Log.w(TAG, "‚ö†Ô∏è Embedding inv√°lido para funcion√°rio ${face.funcionarioId}")
                        allResults.add("Face ${face.funcionarioId}: EMBEDDING INV√ÅLIDO")
                        continue
                    }
                    
                    Log.d(TAG, "üìê Embedding armazenado: ${storedEmbedding.size} dimens√µes")
                    
                    // ‚úÖ Calcular m√©tricas
                    val cosineSimilarity = calculateCosineSimilarity(embedding, storedEmbedding)
                    val euclideanDistance = calculateEuclideanDistance(embedding, storedEmbedding)
                    val confidence = (cosineSimilarity + (1f - (euclideanDistance / 2f))) / 2f // Normalizar dist√¢ncia
                    
                    val resultado = "Face ${face.funcionarioId}: Sim=${String.format("%.3f", cosineSimilarity)}, Dist=${String.format("%.3f", euclideanDistance)}, Conf=${String.format("%.3f", confidence)}"
                    allResults.add(resultado)
                    Log.d(TAG, "üìä $resultado")
                    
                    // ‚úÖ VALIDA√á√ÉO ADAPTATIVA: Usar thresholds baseados no dispositivo
                    val similarityOk = cosineSimilarity >= adaptiveConfig.minSimilarityThreshold
                    val distanceOk = euclideanDistance <= adaptiveConfig.maxEuclideanDistance
                    val confidenceOk = confidence >= adaptiveConfig.requiredConfidence
                    
                    Log.d(TAG, "‚úÖ Valida√ß√µes: Sim=${similarityOk}, Dist=${distanceOk}, Conf=${confidenceOk}")
                    
                    if (similarityOk && distanceOk && confidenceOk) {
                        Log.d(TAG, "üéØ CANDIDATO V√ÅLIDO encontrado!")
                        
                        // ‚úÖ Se encontrou uma correspond√™ncia v√°lida, verificar se √© melhor
                        if (confidence > bestConfidence) {
                            val funcionarioId = face.funcionarioId.toIntOrNull()
                            val funcionarioEncontrado = if (funcionarioId != null) {
                                funcionarios.find { it.id == funcionarioId }
                            } else {
                                funcionarios.find { it.codigo == face.funcionarioId }
                            }
                            
                            if (funcionarioEncontrado != null) {
                                bestMatch = funcionarioEncontrado
                                bestSimilarity = cosineSimilarity
                                bestEuclideanDistance = euclideanDistance
                                bestConfidence = confidence
                                
                                Log.d(TAG, "üéØ NOVO MELHOR MATCH: ${bestMatch.nome} (Confian√ßa: ${String.format("%.3f", confidence)})")
                            } else {
                                Log.w(TAG, "‚ö†Ô∏è Funcion√°rio n√£o encontrado para ID: ${face.funcionarioId}")
                            }
                        }
                    } else {
                        Log.d(TAG, "‚ùå Candidato rejeitado pelos thresholds")
                    }
                    
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao comparar com face ${face.funcionarioId}: ${e.message}")
                    allResults.add("Face ${face.funcionarioId}: ERRO - ${e.message}")
                }
            }
            
            // ‚úÖ LOG DETALHADO DE TODOS OS RESULTADOS
            Log.d(TAG, "üìã === RESUMO DE TODAS AS COMPARA√á√ïES ===")
            allResults.forEach { resultado ->
                Log.d(TAG, "üìä $resultado")
            }
            
            // ‚úÖ RESULTADO FINAL
            if (bestMatch != null) {
                Log.d(TAG, "‚úÖ === RECONHECIMENTO BEM-SUCEDIDO ===")
                Log.d(TAG, "üë§ Funcion√°rio: ${bestMatch.nome}")
                Log.d(TAG, "üÜî ID: ${bestMatch.id}, C√≥digo: ${bestMatch.codigo}")
                Log.d(TAG, "üìä M√©tricas Finais: Similaridade=${String.format("%.3f", bestSimilarity)}, Dist√¢ncia=${String.format("%.3f", bestEuclideanDistance)}, Confian√ßa=${String.format("%.3f", bestConfidence)}")
                
                return FaceRecognitionResult.Success(
                    funcionario = bestMatch,
                    similarity = bestSimilarity,
                    euclideanDistance = bestEuclideanDistance,
                    confidence = bestConfidence
                )
            } else {
                Log.w(TAG, "‚ùå === NENHUM FUNCION√ÅRIO RECONHECIDO ===")
                Log.w(TAG, "üìä Thresholds: Similaridade‚â•${adaptiveConfig.minSimilarityThreshold}, Dist√¢ncia‚â§${adaptiveConfig.maxEuclideanDistance}, Confian√ßa‚â•${adaptiveConfig.requiredConfidence}")
                Log.w(TAG, "üìã Motivo: Nenhuma face atendeu aos crit√©rios m√≠nimos")
                
                return FaceRecognitionResult.Failure("Face n√£o reconhecida - nenhuma correspond√™ncia encontrada nos ${faces.size} registros")
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro cr√≠tico no reconhecimento adaptativo", e)
            e.printStackTrace()
            return FaceRecognitionResult.Failure("Erro interno do sistema: ${e.message}")
        }
    }
    
    /**
     * üñºÔ∏è PROCESSAMENTO DE IMAGEM ADAPTATIVO
     */
    private fun processImageAdaptive(bitmap: Bitmap): Bitmap? {
        return try {
            Log.d(TAG, "üñºÔ∏è Processando imagem adaptativamente...")
            
            // ‚úÖ Redimensionar baseado na qualidade do dispositivo
            val targetSize = adaptiveConfig.maxImageSize
            val processedBitmap = if (bitmap.width != targetSize || bitmap.height != targetSize) {
                Log.d(TAG, "üìè Redimensionando de ${bitmap.width}x${bitmap.height} para ${targetSize}x${targetSize}")
                Bitmap.createScaledBitmap(bitmap, targetSize, targetSize, true)
            } else {
                bitmap
            }
            
            Log.d(TAG, "‚úÖ Imagem processada: ${processedBitmap.width}x${processedBitmap.height}")
            processedBitmap
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro no processamento de imagem: ${e.message}")
            null
        }
    }
    
    /**
     * üìê VALIDA√á√ÉO DE QUALIDADE ADAPTATIVA
     */
    private suspend fun validateImageQualityAdaptive(bitmap: Bitmap): QualityCheckResult {
        return try {
            // ‚úÖ Verificar tamanho m√≠nimo
            if (bitmap.width < 100 || bitmap.height < 100) {
                return QualityCheckResult(false, "Imagem muito pequena (${bitmap.width}x${bitmap.height})")
            }
            
            // ‚úÖ Verificar se n√£o est√° reciclada
            if (bitmap.isRecycled) {
                return QualityCheckResult(false, "Imagem reciclada")
            }
            
            // ‚úÖ Verificar brilho e contraste (mais permissivo para dispositivos fracos)
            val brightness = calculateBrightness(bitmap)
            val contrast = calculateContrast(bitmap)
            
            Log.d(TAG, "üìä Qualidade: Brilho=${String.format("%.3f", brightness)}, Contraste=${String.format("%.3f", contrast)}")
            
            if (brightness < adaptiveConfig.minBrightness || brightness > adaptiveConfig.maxBrightness) {
                return QualityCheckResult(false, "Brilho inadequado (${String.format("%.3f", brightness)})")
            }
            
            if (contrast < adaptiveConfig.minContrast) {
                return QualityCheckResult(false, "Contraste baixo (${String.format("%.3f", contrast)})")
            }
            
            QualityCheckResult(true, "Qualidade adequada")
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro na valida√ß√£o de qualidade: ${e.message}")
            QualityCheckResult(false, "Erro na valida√ß√£o: ${e.message}")
        }
    }
    
    /**
     * üë§ VALIDA√á√ÉO DE DETEC√á√ÉO DE FACE ADAPTATIVA
     */
    private suspend fun validateFaceDetectionAdaptive(bitmap: Bitmap): FaceValidationResult {
        return try {
            val image = InputImage.fromBitmap(bitmap, 0)
            val faces = faceDetector.process(image).await()
            
            if (faces.isEmpty()) {
                return FaceValidationResult(false, "Nenhuma face detectada", null)
            }
            
            if (faces.size > 1) {
                return FaceValidationResult(false, "M√∫ltiplas faces detectadas", null)
            }
            
            val face = faces[0]
            
            // ‚úÖ Verificar tamanho da face (adaptativo)
            val faceRatio = calculateFaceRatio(face.boundingBox, bitmap.width, bitmap.height)
            Log.d(TAG, "üìê Propor√ß√£o da face: ${String.format("%.3f", faceRatio)}")
            
            if (faceRatio < adaptiveConfig.minFaceSizeRatio || faceRatio > adaptiveConfig.maxFaceSizeRatio) {
                return FaceValidationResult(false, "Face muito pequena ou muito grande (${String.format("%.1f", faceRatio * 100)}%)", face)
            }
            
            // ‚úÖ Verificar landmarks (mais permissivo para dispositivos fracos)
            if (adaptiveConfig.imageQuality != DeviceCapabilityHelper.ImageQuality.LOW) {
                val leftEye = face.getLandmark(FaceLandmark.LEFT_EYE)
                val rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE)
                
                if (leftEye == null || rightEye == null) {
                    return FaceValidationResult(false, "Olhos n√£o detectados", face)
                }
                
                val eyeDistance = calculateEyeDistance(face)
                Log.d(TAG, "üëÄ Dist√¢ncia entre olhos: ${String.format("%.1f", eyeDistance)}px")
                
                if (eyeDistance < adaptiveConfig.minEyeDistance) {
                    return FaceValidationResult(false, "Olhos muito pr√≥ximos (${String.format("%.1f", eyeDistance)}px)", face)
                }
            }
            
            return FaceValidationResult(true, "Face v√°lida", face)
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro na valida√ß√£o de face: ${e.message}")
            return FaceValidationResult(false, "Erro na detec√ß√£o: ${e.message}", null)
        }
    }
    
    /**
     * ü§ñ CARREGAR MODELO TENSORFLOW ADAPTATIVO
     */
    private fun loadTensorFlowModel() {
        Log.d(TAG, "ü§ñ Carregando modelo TensorFlow adaptativo...")
        
        try {
            // ‚úÖ Usar configura√ß√µes otimizadas para o dispositivo
            val options = Interpreter.Options().apply {
                setNumThreads(
                    when (deviceInfo.performanceLevel) {
                        PerformanceLevel.LOW -> 1
                        PerformanceLevel.MEDIUM -> 2
                        PerformanceLevel.HIGH -> 4
                        else -> 2 // Fallback para casos inesperados
                    }
                )
                setUseNNAPI(adaptiveConfig.useTensorFlowOptimizations)
                setAllowFp16PrecisionForFp32(adaptiveConfig.useTensorFlowOptimizations)
                setAllowBufferHandleOutput(false)
            }
            
            // ‚úÖ Carregar modelo
            val modelFile = try {
                context.assets.open("facenet_model.tflite")
            } catch (e: Exception) {
                context.resources.openRawResource(com.example.iface_offilne.R.raw.mobilefacenet)
            }
            
            val modelBuffer = modelFile.use { input ->
                val bytes = ByteArray(input.available())
                input.read(bytes)
                ByteBuffer.allocateDirect(bytes.size).apply {
                    order(ByteOrder.nativeOrder())
                    put(bytes)
                    rewind()
                }
            }
            
            interpreter = Interpreter(modelBuffer, options)
            modelLoaded = true
            
            Log.d(TAG, "‚úÖ Modelo TensorFlow carregado com configura√ß√µes adaptativas")
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao carregar modelo TensorFlow: ${e.message}")
            modelLoaded = false
        }
    }
    
    /**
     * üî¢ GERAR EMBEDDING FACIAL
     */
    private fun generateFaceEmbedding(bitmap: Bitmap): FloatArray? {
        return try {
            if (!modelLoaded || interpreter == null) {
                Log.e(TAG, "‚ùå Modelo n√£o carregado")
                return null
            }
            
            val inputTensor = convertBitmapToTensorInput(bitmap)
            val output = Array(1) { FloatArray(512) } // Tamanho padr√£o do embedding
            
            interpreter?.run(inputTensor, output)
            
            val embedding = output[0]
            Log.d(TAG, "‚úÖ Embedding gerado: ${embedding.size} dimens√µes")
            
            embedding
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao gerar embedding: ${e.message}")
            null
        }
    }
    
    /**
     * üìä CALCULAR QUALIDADE DA IMAGEM
     */
    private fun calculateImageQuality(bitmap: Bitmap): ImageQuality {
        return try {
            val pixels = IntArray(bitmap.width * bitmap.height)
            bitmap.getPixels(pixels, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)
            
            var totalBrightness = 0f
            var totalContrast = 0f
            
            for (pixel in pixels) {
                val r = (pixel shr 16) and 0xFF
                val g = (pixel shr 8) and 0xFF
                val b = pixel and 0xFF
                
                val brightness = (r + g + b) / 3f / 255f
                totalBrightness += brightness
            }
            
            val avgBrightness = totalBrightness / pixels.size
            
            // Calcular contraste simples
            val contrast = 0.5f // Valor padr√£o para simplicidade
            
            ImageQuality(avgBrightness, contrast)
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao calcular qualidade: ${e.message}")
            ImageQuality(0.5f, 0.5f) // Valores padr√£o
        }
    }
    
    /**
     * ü§ñ GERAR EMBEDDING DA FACE
     */
    private fun generateEmbedding(bitmap: Bitmap): FloatArray {
        return try {
            // ‚úÖ REDIMENSIONAR PARA O TAMANHO DO MODELO
            val resizedBitmap = if (bitmap.width != 160 || bitmap.height != 160) {
                Bitmap.createScaledBitmap(bitmap, 160, 160, true)
            } else {
                bitmap
            }
            
            // ‚úÖ CONVERTER PARA TENSOR
            val inputTensor = convertBitmapToTensorInput(resizedBitmap)
            val output = Array(1) { FloatArray(512) }
            
            // ‚úÖ EXECUTAR MODELO
            interpreter?.run(inputTensor, output)
            val embedding = output[0]
            
            // ‚úÖ VALIDAR EMBEDDING
            if (embedding.isEmpty() || embedding.all { it == 0f } || embedding.any { it.isNaN() || it.isInfinite() }) {
                throw Exception("Embedding inv√°lido gerado")
            }
            
            Log.d(TAG, "‚úÖ Embedding gerado com sucesso: ${embedding.size} dimens√µes")
            embedding
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao gerar embedding: ${e.message}")
            throw e
        }
    }
    
    /**
     * üîß CONVERTER BITMAP PARA TENSOR
     */
    private fun convertBitmapToTensorInput(bitmap: Bitmap): ByteBuffer {
        val inputSize = 160
        val byteBuffer = ByteBuffer.allocateDirect(4 * inputSize * inputSize * 3)
        byteBuffer.order(ByteOrder.nativeOrder())
        
        val intValues = IntArray(inputSize * inputSize)
        bitmap.getPixels(intValues, 0, inputSize, 0, 0, inputSize, inputSize)
        
        for (pixel in intValues) {
            val r = ((pixel shr 16) and 0xFF) / 127.5f - 1.0f
            val g = ((pixel shr 8) and 0xFF) / 127.5f - 1.0f
            val b = (pixel and 0xFF) / 127.5f - 1.0f
            
            byteBuffer.putFloat(r)
            byteBuffer.putFloat(g)
            byteBuffer.putFloat(b)
        }
        
        return byteBuffer
    }
    
    // ========== M√âTODOS AUXILIARES ==========
    
    private fun calculateCosineSimilarity(embedding1: FloatArray, embedding2: FloatArray): Float {
        if (embedding1.size != embedding2.size) return 0f
        
        var dotProduct = 0f
        var norm1 = 0f
        var norm2 = 0f
        
        for (i in embedding1.indices) {
            dotProduct += embedding1[i] * embedding2[i]
            norm1 += embedding1[i] * embedding1[i]
            norm2 += embedding2[i] * embedding2[i]
        }
        
        val denominator = sqrt(norm1) * sqrt(norm2)
        return if (denominator > 0f) dotProduct / denominator else 0f
    }
    
    private fun calculateEuclideanDistance(embedding1: FloatArray, embedding2: FloatArray): Float {
        if (embedding1.size != embedding2.size) return Float.MAX_VALUE
        
        var sum = 0f
        for (i in embedding1.indices) {
            val diff = embedding1[i] - embedding2[i]
            sum += diff * diff
        }
        
        return sqrt(sum)
    }
    
    private fun parseEmbedding(embeddingString: String): FloatArray? {
        return try {
            embeddingString.split(",").map { it.trim().toFloat() }.toFloatArray()
        } catch (e: Exception) {
            null
        }
    }
    
    private fun calculateFaceRatio(boundingBox: Rect, imageWidth: Int, imageHeight: Int): Float {
        val faceArea = boundingBox.width() * boundingBox.height()
        val imageArea = imageWidth * imageHeight
        return faceArea.toFloat() / imageArea.toFloat()
    }
    
    private fun calculateEyeDistance(face: Face): Float {
        val leftEye = face.getLandmark(FaceLandmark.LEFT_EYE)
        val rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE)
        
        if (leftEye == null || rightEye == null) return 0f
        
        val dx = leftEye.position.x - rightEye.position.x
        val dy = leftEye.position.y - rightEye.position.y
        return sqrt(dx * dx + dy * dy)
    }
    
    private fun calculateBrightness(bitmap: Bitmap): Float {
        val pixels = IntArray(bitmap.width * bitmap.height)
        bitmap.getPixels(pixels, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)
        
        var totalBrightness = 0f
        for (pixel in pixels) {
            val r = (pixel shr 16) and 0xFF
            val g = (pixel shr 8) and 0xFF
            val b = pixel and 0xFF
            totalBrightness += (r + g + b) / 3f / 255f
        }
        
        return totalBrightness / pixels.size
    }
    
    private fun calculateContrast(bitmap: Bitmap): Float {
        val pixels = IntArray(bitmap.width * bitmap.height)
        bitmap.getPixels(pixels, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)
        
        var totalBrightness = 0f
        for (pixel in pixels) {
            val r = (pixel shr 16) and 0xFF
            val g = (pixel shr 8) and 0xFF
            val b = pixel and 0xFF
            totalBrightness += (r + g + b) / 3f / 255f
        }
        
        val averageBrightness = totalBrightness / pixels.size
        
        var variance = 0f
        for (pixel in pixels) {
            val r = (pixel shr 16) and 0xFF
            val g = (pixel shr 8) and 0xFF
            val b = pixel and 0xFF
            val brightness = (r + g + b) / 3f / 255f
            variance += (brightness - averageBrightness) * (brightness - averageBrightness)
        }
        
        return sqrt(variance / pixels.size)
    }
    
    // ========== CLASSES DE RESULTADO ==========
    
    sealed class FaceRecognitionResult {
        data class Success(
            val funcionario: com.example.iface_offilne.data.FuncionariosEntity,
            val similarity: Float,
            val euclideanDistance: Float,
            val confidence: Float
        ) : FaceRecognitionResult()
        data class Failure(val reason: String) : FaceRecognitionResult()
    }
    
    data class QualityCheckResult(val isValid: Boolean, val reason: String)
    
    data class FaceValidationResult(val isValid: Boolean, val reason: String, val face: Face?)
    
    /**
     * üìä CLASSE PARA QUALIDADE DA IMAGEM
     */
    data class ImageQuality(
        val brightness: Float,
        val contrast: Float
    )
} 