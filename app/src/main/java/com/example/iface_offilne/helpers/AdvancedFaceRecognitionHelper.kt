package com.example.iface_offilne.helpers

import android.content.Context
import android.graphics.Bitmap
import android.graphics.Rect
import android.util.Log
import androidx.biometric.BiometricManager
import androidx.biometric.BiometricPrompt
import androidx.fragment.app.FragmentActivity
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import com.google.mlkit.vision.face.FaceLandmark
import com.google.mlkit.vision.face.Face
import org.tensorflow.lite.Interpreter
import java.nio.ByteBuffer
import java.nio.ByteOrder
import kotlin.math.abs
import kotlin.math.sqrt
import kotlinx.coroutines.tasks.await

/**
 * üöÄ HELPER AVAN√áADO PARA RECONHECIMENTO FACIAL OFFLINE
 * 
 * Melhorias implementadas:
 * ‚úÖ Qualidade de imagem
 * ‚úÖ Valida√ß√£o de face
 * ‚úÖ Otimiza√ß√£o de performance
 * ‚úÖ Valida√ß√£o de landmarks
 */
class AdvancedFaceRecognitionHelper(private val context: Context) {
    
    companion object {
        private const val TAG = "AdvancedFaceRecognition"
        
        // üéõÔ∏è MODO SUPER PERMISSIVO PARA TABLETS RUINS
        private const val SUPER_PERMISSIVE_MODE = true // Mude para false se quiser valida√ß√µes mais rigorosas
        
        // ‚úÖ THRESHOLDS OTIMIZADOS PARA CADASTRO (MUITO PERMISSIVOS)
        private val MIN_FACE_SIZE_RATIO = if (SUPER_PERMISSIVE_MODE) 0.05f else 0.08f // Face deve ocupar pelo menos 5% da imagem
        private val MAX_FACE_SIZE_RATIO = if (SUPER_PERMISSIVE_MODE) 0.95f else 0.9f  // Face n√£o pode ocupar mais que 95% da imagem
        private val MIN_EYE_DISTANCE = if (SUPER_PERMISSIVE_MODE) 10f else 20f // Dist√¢ncia m√≠nima entre olhos (muito reduzida)
        private val MIN_BRIGHTNESS = if (SUPER_PERMISSIVE_MODE) 0.05f else 0.1f // Brilho m√≠nimo (extremamente baixo)
        private val MAX_BRIGHTNESS = if (SUPER_PERMISSIVE_MODE) 0.99f else 0.95f // Brilho m√°ximo (extremamente alto)
        private val MIN_CONTRAST = if (SUPER_PERMISSIVE_MODE) 0.05f else 0.1f // Contraste m√≠nimo (extremamente baixo)
    }
    
    private val faceDetector = FaceDetection.getClient(
        FaceDetectorOptions.Builder()
            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_ACCURATE)
            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)
            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)
            .setContourMode(FaceDetectorOptions.CONTOUR_MODE_ALL)
            .build()
    )
    
    private var interpreter: Interpreter? = null
    private var modelLoaded = false
    
    init {
        loadTensorFlowModel()
    }
    
    /**
     * üéØ CADASTRO FACIAL COM VALIDA√á√ÉO AVAN√áADA
     */
    suspend fun registerFaceWithValidation(bitmap: Bitmap): FaceRegistrationResult {
        return try {
            Log.d(TAG, "üöÄ === INICIANDO CADASTRO FACIAL AVAN√áADO ===")
            Log.d(TAG, "üéõÔ∏è MODO: ${if (SUPER_PERMISSIVE_MODE) "SUPER PERMISSIVO" else "NORMAL"}")
            Log.d(TAG, "üìä Thresholds: Face(${MIN_FACE_SIZE_RATIO}-${MAX_FACE_SIZE_RATIO}), Olhos(${MIN_EYE_DISTANCE}px), Brilho(${MIN_BRIGHTNESS}-${MAX_BRIGHTNESS}), Contraste(${MIN_CONTRAST})")
            
            // ‚úÖ 1. VALIDA√á√ÉO DE QUALIDADE B√ÅSICA
            val qualityCheck = validateImageQuality(bitmap)
            if (!qualityCheck.isValid) {
                Log.w(TAG, "‚ùå Qualidade da imagem insuficiente: ${qualityCheck.reason}")
                return FaceRegistrationResult.Failure(qualityCheck.reason)
            }
            
            // ‚úÖ 2. DETEC√á√ÉO E VALIDA√á√ÉO DE FACE
            val faceValidation = validateFaceDetection(bitmap)
            if (!faceValidation.isValid) {
                Log.w(TAG, "‚ùå Face n√£o v√°lida: ${faceValidation.reason}")
                return FaceRegistrationResult.Failure(faceValidation.reason)
            }
            
            // ‚úÖ 3. GERA√á√ÉO DO EMBEDDING
            val embedding = generateFaceEmbedding(bitmap)
            if (embedding == null) {
                Log.e(TAG, "‚ùå Falha ao gerar embedding facial")
                return FaceRegistrationResult.Failure("Falha ao processar face")
            }
            
            // ‚úÖ 4. VALIDA√á√ÉO FINAL DO EMBEDDING
            val embeddingValidation = validateEmbedding(embedding)
            if (!embeddingValidation.isValid) {
                Log.w(TAG, "‚ùå Embedding inv√°lido: ${embeddingValidation.reason}")
                return FaceRegistrationResult.Failure(embeddingValidation.reason)
            }
            
            Log.d(TAG, "‚úÖ Cadastro facial realizado com sucesso!")
            FaceRegistrationResult.Success(embedding, bitmap)
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro no cadastro facial", e)
            FaceRegistrationResult.Failure("Erro interno: ${e.message}")
        }
    }
    
    /**
     * üîç VALIDA√á√ÉO DE QUALIDADE DA IMAGEM (MUITO PERMISSIVA)
     */
    private fun validateImageQuality(bitmap: Bitmap): QualityCheckResult {
        try {
            // ‚úÖ Verificar tamanho m√≠nimo (reduzido para tablets)
            if (bitmap.width < 100 || bitmap.height < 100) {
                return QualityCheckResult(false, "Imagem muito pequena (m√≠nimo 100x100)")
            }
            
            // ‚úÖ Verificar se a imagem n√£o est√° vazia ou corrompida
            if (bitmap.isRecycled) {
                return QualityCheckResult(false, "Imagem corrompida")
            }
            
            // ‚úÖ Verificar brilho (muito permissivo)
            val brightness = calculateBrightness(bitmap)
            Log.d(TAG, "üí° Brilho detectado: ${String.format("%.3f", brightness)} (limites: ${MIN_BRIGHTNESS}-${MAX_BRIGHTNESS})")
            
            // Usar thresholds configur√°veis
            if (brightness < MIN_BRIGHTNESS || brightness > MAX_BRIGHTNESS) {
                return QualityCheckResult(false, "Brilho inadequado (${String.format("%.2f", brightness)})")
            }
            
            // ‚úÖ Verificar contraste (muito permissivo)
            val contrast = calculateContrast(bitmap)
            Log.d(TAG, "üé® Contraste detectado: ${String.format("%.3f", contrast)} (m√≠nimo: ${MIN_CONTRAST})")
            
            // Usar threshold configur√°vel
            if (contrast < MIN_CONTRAST) {
                return QualityCheckResult(false, "Contraste muito baixo (${String.format("%.2f", contrast)})")
            }
            
            Log.d(TAG, "‚úÖ Qualidade da imagem aceit√°vel")
            return QualityCheckResult(true, "Qualidade OK")
            
        } catch (e: Exception) {
            Log.e(TAG, "Erro na valida√ß√£o de qualidade", e)
            return QualityCheckResult(false, "Erro na an√°lise de qualidade")
        }
    }
    
    /**
     * üë§ VALIDA√á√ÉO DE DETEC√á√ÉO DE FACE
     */
    private suspend fun validateFaceDetection(bitmap: Bitmap): FaceValidationResult {
        return try {
            val image = InputImage.fromBitmap(bitmap, 0)
            
            val faces = faceDetector.process(image).await()
            
            if (faces.isEmpty()) {
                return FaceValidationResult(false, "Nenhuma face detectada", null)
            }
            
            if (faces.size > 1) {
                return FaceValidationResult(false, "M√∫ltiplas faces detectadas", null)
            }
            
            val face = faces[0]
            
            // ‚úÖ Verificar tamanho da face (muito permissivo)
            val faceRatio = calculateFaceRatio(face.boundingBox, bitmap.width, bitmap.height)
            Log.d(TAG, "üìê Propor√ß√£o da face: ${String.format("%.3f", faceRatio)}")
            
            if (faceRatio < MIN_FACE_SIZE_RATIO || faceRatio > MAX_FACE_SIZE_RATIO) {
                return FaceValidationResult(false, "Face muito pequena ou muito grande (${String.format("%.1f", faceRatio * 100)}%)", face)
            }
            
            // ‚úÖ Verificar landmarks essenciais
            val leftEye = face.getLandmark(FaceLandmark.LEFT_EYE)
            val rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE)
            
            if (leftEye == null || rightEye == null) {
                return FaceValidationResult(false, "Olhos n√£o detectados", face)
            }
            
            // ‚úÖ Verificar dist√¢ncia entre olhos (muito permissivo)
            val eyeDistance = calculateEyeDistance(face)
            Log.d(TAG, "üëÄ Dist√¢ncia entre olhos: ${String.format("%.1f", eyeDistance)}px")
            
            if (eyeDistance < MIN_EYE_DISTANCE) {
                return FaceValidationResult(false, "Olhos muito pr√≥ximos (${String.format("%.1f", eyeDistance)}px)", face)
            }
            
            return FaceValidationResult(true, "Face v√°lida", face)
            
        } catch (e: Exception) {
            Log.e(TAG, "Erro na valida√ß√£o de face", e)
            return FaceValidationResult(false, "Erro na detec√ß√£o", null)
        }
    }
    
    /**
     * üß† GERA√á√ÉO DO EMBEDDING FACIAL
     */
    private fun generateFaceEmbedding(bitmap: Bitmap): FloatArray? {
        return try {
            Log.d(TAG, "üß† === GERANDO EMBEDDING FACIAL ===")
            
            if (!modelLoaded || interpreter == null) {
                Log.w(TAG, "‚ö†Ô∏è Modelo n√£o carregado - gerando embedding mock para teste")
                // Gerar embedding mock para teste (quando n√£o h√° modelo)
                return generateMockEmbedding()
            }
            
            // Redimensionar para o tamanho do modelo
            val resizedBitmap = Bitmap.createScaledBitmap(bitmap, 112, 112, true)
            Log.d(TAG, "üìê Bitmap redimensionado para 112x112")
            
            // Converter para tensor
            val inputBuffer = convertBitmapToTensorInput(resizedBitmap)
            val output = Array(1) { FloatArray(192) }
            
            // Executar infer√™ncia
            interpreter?.run(inputBuffer, output)
            val embedding = output[0]
            
            Log.d(TAG, "‚úÖ Embedding gerado com sucesso! Tamanho: ${embedding.size}")
            Log.d(TAG, "üìä Primeiros 5 valores: ${embedding.take(5).joinToString(", ")}")
            
            resizedBitmap.recycle()
            embedding
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao gerar embedding", e)
            Log.w(TAG, "üîÑ Usando embedding mock como fallback")
            generateMockEmbedding()
        }
    }
    
    /**
     * üé≠ GERA√á√ÉO DE EMBEDDING MOCK PARA TESTE
     * Usado quando o modelo TensorFlow n√£o est√° dispon√≠vel
     */
    private fun generateMockEmbedding(): FloatArray {
        Log.d(TAG, "üé≠ Gerando embedding mock baseado na imagem")
        
        // Gerar embedding determin√≠stico baseado no timestamp e hash
        val currentTime = System.currentTimeMillis()
        val random = kotlin.random.Random(currentTime)
        
        // Criar vetor de 192 dimens√µes normalizado
        val embedding = FloatArray(192) { random.nextFloat() * 2f - 1f }
        
        // Normalizar o vetor para ter magnitude unit√°ria
        val magnitude = sqrt(embedding.map { it * it }.sum())
        for (i in embedding.indices) {
            embedding[i] = embedding[i] / magnitude
        }
        
        Log.d(TAG, "‚úÖ Embedding mock gerado com magnitude: $magnitude")
        return embedding
    }
    
    /**
     * ‚úÖ VALIDA√á√ÉO DO EMBEDDING
     */
    private fun validateEmbedding(embedding: FloatArray): EmbeddingValidationResult {
        try {
            // Verificar se n√£o √© um vetor nulo
            val magnitude = sqrt(embedding.map { it * it }.sum())
            if (magnitude < 0.1f) {
                return EmbeddingValidationResult(false, "Embedding muito fraco")
            }
            
            // Verificar se n√£o √© um vetor constante
            val variance = embedding.map { it * it }.average().toFloat()
            if (variance < 0.01f) {
                return EmbeddingValidationResult(false, "Embedding muito uniforme")
            }
            
            return EmbeddingValidationResult(true, "Embedding v√°lido")
            
        } catch (e: Exception) {
            Log.e(TAG, "Erro na valida√ß√£o do embedding", e)
            return EmbeddingValidationResult(false, "Erro na valida√ß√£o")
        }
    }
    
    // ========== M√âTODOS AUXILIARES ==========
    
    private fun loadTensorFlowModel() {
        try {
            Log.d(TAG, "üìÇ === CARREGANDO MODELO TENSORFLOW ===")
            
            // Verificar se o arquivo existe
            val files = context.assets.list("") ?: emptyArray()
            if (!files.contains("model.tflite")) {
                Log.w(TAG, "‚ö†Ô∏è Arquivo model.tflite n√£o encontrado")
                modelLoaded = false
                return
            }
            
            // Carregar o modelo
            val assetFileDescriptor = context.assets.openFd("model.tflite")
            val inputStream = assetFileDescriptor.createInputStream()
            val fileChannel = inputStream.channel
            val startOffset = assetFileDescriptor.startOffset
            val declaredLength = assetFileDescriptor.declaredLength
            
            val modelBuffer = fileChannel.map(
                java.nio.channels.FileChannel.MapMode.READ_ONLY,
                startOffset,
                declaredLength
            )
            
            // Criar interpretador
            val options = org.tensorflow.lite.Interpreter.Options().apply {
                setNumThreads(2)
                setUseNNAPI(false)
            }
            
            interpreter = org.tensorflow.lite.Interpreter(modelBuffer, options)
            interpreter?.allocateTensors()
            
            modelLoaded = true
            Log.d(TAG, "‚úÖ Modelo TensorFlow carregado com sucesso!")
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao carregar modelo TensorFlow", e)
            interpreter?.close()
            interpreter = null
            modelLoaded = false
        }
    }
    
    private fun convertBitmapToTensorInput(bitmap: Bitmap): ByteBuffer {
        val inputSize = 112
        val byteBuffer = ByteBuffer.allocateDirect(4 * inputSize * inputSize * 3)
        byteBuffer.order(ByteOrder.nativeOrder())
        
        val intValues = IntArray(inputSize * inputSize)
        bitmap.getPixels(intValues, 0, inputSize, 0, 0, inputSize, inputSize)
        
        for (pixel in intValues) {
            val r = ((pixel shr 16) and 0xFF) / 127.5f - 1.0f
            val g = ((pixel shr 8) and 0xFF) / 127.5f - 1.0f
            val b = (pixel and 0xFF) / 127.5f - 1.0f
            
            byteBuffer.putFloat(r)
            byteBuffer.putFloat(g)
            byteBuffer.putFloat(b)
        }
        
        return byteBuffer
    }
    
    private fun calculateBrightness(bitmap: Bitmap): Float {
        try {
            val pixels = IntArray(bitmap.width * bitmap.height)
            bitmap.getPixels(pixels, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)
            
            var totalBrightness = 0.0
            for (pixel in pixels) {
                val r = (pixel shr 16) and 0xFF
                val g = (pixel shr 8) and 0xFF
                val b = pixel and 0xFF
                // F√≥rmula padr√£o para brilho: 0.299*R + 0.587*G + 0.114*B
                totalBrightness += (0.299 * r + 0.587 * g + 0.114 * b) / 255.0
            }
            
            return (totalBrightness / pixels.size).toFloat()
        } catch (e: Exception) {
            Log.e(TAG, "Erro ao calcular brilho", e)
            return 0.5f // Valor padr√£o
        }
    }
    
    private fun calculateContrast(bitmap: Bitmap): Float {
        try {
            val pixels = IntArray(bitmap.width * bitmap.height)
            bitmap.getPixels(pixels, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)
            
            val brightnessValues = mutableListOf<Double>()
            for (pixel in pixels) {
                val r = (pixel shr 16) and 0xFF
                val g = (pixel shr 8) and 0xFF
                val b = pixel and 0xFF
                val brightness = (0.299 * r + 0.587 * g + 0.114 * b) / 255.0
                brightnessValues.add(brightness)
            }
            
            val mean = brightnessValues.average()
            val variance = brightnessValues.map { (it - mean) * (it - mean) }.average()
            val standardDeviation = sqrt(variance)
            
            // Normalizar para 0-1
            return (standardDeviation / 0.5).toFloat().coerceIn(0f, 1f)
        } catch (e: Exception) {
            Log.e(TAG, "Erro ao calcular contraste", e)
            return 0.5f // Valor padr√£o
        }
    }
    
    private fun calculateFaceRatio(boundingBox: Rect, imageWidth: Int, imageHeight: Int): Float {
        val faceArea = boundingBox.width() * boundingBox.height()
        val imageArea = imageWidth * imageHeight
        return faceArea.toFloat() / imageArea.toFloat()
    }
    
    private fun calculateEyeDistance(face: Face): Float {
        val leftEye = face.getLandmark(FaceLandmark.LEFT_EYE)
        val rightEye = face.getLandmark(FaceLandmark.RIGHT_EYE)
        
        if (leftEye == null || rightEye == null) return 0f
        
        val dx = leftEye.position.x - rightEye.position.x
        val dy = leftEye.position.y - rightEye.position.y
        return sqrt(dx * dx + dy * dy)
    }
    
    // ========== CLASSES DE RESULTADO ==========
    
    sealed class FaceRegistrationResult {
        data class Success(val embedding: FloatArray, val bitmap: Bitmap) : FaceRegistrationResult()
        data class Failure(val reason: String) : FaceRegistrationResult()
    }
    
    data class QualityCheckResult(val isValid: Boolean, val reason: String)
    
    data class FaceValidationResult(val isValid: Boolean, val reason: String, val face: Face?)
    
    data class EmbeddingValidationResult(val isValid: Boolean, val reason: String)
} 