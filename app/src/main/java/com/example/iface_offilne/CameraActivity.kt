package com.example.iface_offilne

import android.Manifest
import android.content.pm.PackageManager
import android.graphics.*
import android.os.Bundle
import android.os.Environment
import android.os.Handler
import android.os.Looper
import android.util.Log
import android.view.View
import android.widget.FrameLayout
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.camera.view.PreviewView
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import com.example.iface_offilne.data.AppDatabase
import com.example.iface_offilne.data.FaceEntity
import com.example.iface_offilne.helpers.AdvancedFaceRecognitionHelper
import com.example.iface_offilne.helpers.Helpers
import com.example.iface_offilne.helpers.bitmapToFloatArray
import com.example.iface_offilne.helpers.cropFace
import com.example.iface_offilne.helpers.fixImageOrientationDefinitive
import com.example.iface_offilne.helpers.toBitmap
import com.example.iface_offilne.models.FacesModel
import com.example.iface_offilne.models.FuncionariosLocalModel
import com.example.iface_offilne.util.FaceOverlayView
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import org.tensorflow.lite.Interpreter
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.io.IOException
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.channels.FileChannel
import java.text.SimpleDateFormat
import java.util.*

class CameraActivity : AppCompatActivity() {

    private lateinit var previewView: PreviewView
    private lateinit var imageAnalyzer: ImageAnalysis
    private lateinit var overlay: FaceOverlayView

    private var interpreter: Interpreter? = null
    private var modelLoaded = false

    private var modelInputWidth = 160
    private var modelInputHeight = 160
    private var modelOutputSize = 192
    
    // üöÄ NOVO: Helper avan√ßado para reconhecimento facial
    private lateinit var advancedFaceHelper: AdvancedFaceRecognitionHelper

    companion object {
        private const val REQUEST_CODE_PERMISSIONS = 10
        private val REQUIRED_PERMISSIONS = when {
            android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.UPSIDE_DOWN_CAKE -> {
                // Android 14+ (API 34+)
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.READ_MEDIA_IMAGES,
                    Manifest.permission.POST_NOTIFICATIONS
                )
            }
            android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.TIRAMISU -> {
                // Android 13+ (API 33+)
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.READ_MEDIA_IMAGES
                )
            }
            else -> {
                // Android 12 e abaixo
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.WRITE_EXTERNAL_STORAGE,
                    Manifest.permission.READ_EXTERNAL_STORAGE
                )
            }
        }
        private const val TAG = "CameraActivity"

        // Assinatura de arquivo TFLite v√°lido
        private val TFLITE_SIGNATURE = byteArrayOf(0x54, 0x46, 0x4C, 0x33) // "TFL3"
    }

    private var faceDetector = FaceDetection.getClient(
        FaceDetectorOptions.Builder()
            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST) // ‚úÖ SIMPLIFICA√á√ÉO: Modo r√°pido para melhor performance
            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_NONE)
            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_NONE)
            .setMinFaceSize(0.1f) // ‚úÖ SIMPLIFICA√á√ÉO: Face ainda menor para detectar qualquer rosto
            .build()
    )

    private var alreadySaved = false
    private var faceDetectionCount = 0
    private var currentFaceBitmap: Bitmap? = null
    
    // ‚úÖ SISTEMA DE ESTABILIZA√á√ÉO: Aguardar usu√°rio se posicionar adequadamente
    private var faceStableCount = 0 // Contador de frames est√°veis
    private var lastFacePosition: Rect? = null // √öltima posi√ß√£o da face
    private var faceStableStartTime = 0L // Tempo de in√≠cio da estabiliza√ß√£o
    private var minStableFrames = 40 // M√≠nimo de frames est√°veis (1.5 segundos a 10fps)
    private var maxStableTime = 8000L // M√°ximo 5 segundos para estabilizar
    private var positionTolerance = 90 // Toler√¢ncia em pixels para considerar est√°vel
    private var isProcessingFace = false // Evitar m√∫ltiplos processamentos

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        setupUI()
        Log.d(TAG, "üöÄ === INICIANDO APLICA√á√ÉO ===")

        // üöÄ NOVO: Inicializar helper avan√ßado
        advancedFaceHelper = AdvancedFaceRecognitionHelper(this)
        
        // üîç TESTE: Verificar banco de dados
        testDatabaseConnection()
        
        // ‚úÖ NOVO: Validar embeddings existentes (APENAS VERIFICA√á√ÉO, SEM REMO√á√ÉO)
        validateExistingEmbeddings()
        
        // ‚úÖ NOVO: Detectar qualidade da c√¢mera e ajustar par√¢metros
        detectCameraQuality()
        
        // Carrega o modelo
        loadTensorFlowModel()

        // Solicita permiss√µes
        Log.d(TAG, "üîê Verificando permiss√µes...")
        Log.d(TAG, "üì± Vers√£o Android: ${android.os.Build.VERSION.SDK_INT}")
        Log.d(TAG, "üìã Permiss√µes necess√°rias: ${REQUIRED_PERMISSIONS.joinToString(", ")}")
        
        if (allPermissionsGranted()) {
            Log.d(TAG, "‚úÖ Todas as permiss√µes j√° concedidas")
            startCamera()
            
            // ‚úÖ INSTRU√á√ïES DETALHADAS PARA POSICIONAMENTO
            Handler(Looper.getMainLooper()).postDelayed({
                showToast("üì∑ Posicione seu rosto no oval\nFique parado por 2 segundos")
            }, 2000)
            
            // ‚úÖ INSTRU√á√ïES ADICIONAIS
            Handler(Looper.getMainLooper()).postDelayed({
                showToast("üì∑ Sistema aguardando estabiliza√ß√£o...\nMantenha o rosto no centro")
            }, 5000)
        } else {
            Log.d(TAG, "‚ùå Permiss√µes pendentes - solicitando...")
            // Mostrar mensagem informativa antes de solicitar permiss√µes
            Toast.makeText(this, "üì∑ O app precisa de permiss√£o para c√¢mera e armazenamento para registrar sua face", Toast.LENGTH_LONG).show()
            ActivityCompat.requestPermissions(this, REQUIRED_PERMISSIONS, REQUEST_CODE_PERMISSIONS)
        }
    }

    private fun setupUI() {
        previewView = PreviewView(this).apply { id = View.generateViewId() }
        overlay = FaceOverlayView(this).apply { id = View.generateViewId() }

        val container = FrameLayout(this).apply {
            layoutParams = FrameLayout.LayoutParams(
                FrameLayout.LayoutParams.MATCH_PARENT,
                FrameLayout.LayoutParams.MATCH_PARENT
            )
            addView(previewView)
        }
        container.addView(overlay)
        setContentView(container)
    }

    private fun loadTensorFlowModel() {
        try {
            Log.d(TAG, "üìÇ === CARREGANDO MODELO TENSORFLOW LITE ===")
            listAssetsFiles()

            // ‚úÖ VERIFICAR SE O ARQUIVO EXISTE
            if (!checkModelExists()) {
                Log.w(TAG, "‚ö†Ô∏è Arquivo model.tflite n√£o encontrado")
                showToast("‚ö†Ô∏è Modelo n√£o encontrado - usando modo de detec√ß√£o apenas")
                return
            }

            // ‚úÖ VALIDAR O ARQUIVO
            if (!validateModelFile()) {
                Log.e(TAG, "‚ùå Arquivo model.tflite √© inv√°lido!")
                showToast("‚ùå Modelo corrompido - usando modo de detec√ß√£o apenas")
                return
            }

            // ‚úÖ CARREGAR O ARQUIVO
            val buffer = loadModelFile("model.tflite")
            Log.d(TAG, "‚úÖ Buffer carregado! Tamanho: ${buffer.capacity()} bytes")

            // ‚úÖ CRIAR INTERPRETER COM CONFIGURA√á√ïES OTIMIZADAS
            val options = Interpreter.Options().apply {
                setNumThreads(4) // Mais threads para melhor performance
                setUseNNAPI(false) // Desabilitar NNAPI para compatibilidade
                setAllowFp16PrecisionForFp32(false) // Usar precis√£o FP32
            }

            interpreter = Interpreter(buffer, options)
            interpreter?.allocateTensors()

            Log.d(TAG, "‚úÖ Interpreter criado e tensores alocados!")

            // ‚úÖ VERIFICAR DIMENS√ïES DO MODELO
            if (checkAndExtractModelDimensions()) {
                modelLoaded = true
                Log.d(TAG, "üéØ === MODELO TENSORFLOW LITE CARREGADO COM SUCESSO ===")
                Log.d(TAG, "üìä Dimens√µes de entrada: ${modelInputWidth}x${modelInputHeight}")
                Log.d(TAG, "üìä Dimens√µes de sa√≠da: ${modelOutputSize}")
                Log.d(TAG, "ü§ñ Interpreter: ${interpreter != null}")
                showToast("‚úÖ Modelo TensorFlow Lite carregado!")
            } else {
                Log.w(TAG, "‚ö†Ô∏è Dimens√µes do modelo n√£o puderam ser extra√≠das - usando padr√£o")
                // Usar dimens√µes padr√£o se n√£o conseguir extrair
                modelInputWidth = 160
                modelInputHeight = 160
                modelOutputSize = 192
                modelLoaded = true
                Log.d(TAG, "üîÑ Usando dimens√µes padr√£o: 160x160 ‚Üí 192")
            }

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro cr√≠tico ao carregar modelo: ${e.javaClass.simpleName}", e)
            e.printStackTrace()

            when {
                e.message?.contains("flatbuffer") == true -> {
                    Log.e(TAG, "üí° DIAGN√ìSTICO: Arquivo n√£o √© um modelo TFLite v√°lido")
                    showToast("‚ùå Modelo inv√°lido - usando detec√ß√£o apenas")
                }
                e.message?.contains("not found") == true -> {
                    Log.e(TAG, "üí° DIAGN√ìSTICO: Arquivo model.tflite n√£o encontrado")
                    showToast("‚ö†Ô∏è Modelo n√£o encontrado - usando detec√ß√£o apenas")
                }
                else -> {
                    Log.e(TAG, "üí° DIAGN√ìSTICO: Erro desconhecido no modelo")
                    showToast("‚ùå Erro no modelo: ${e.message}")
                }
            }

            // ‚úÖ LIMPAR RECURSOS EM CASO DE ERRO
            interpreter?.close()
            interpreter = null
            modelLoaded = false

            Log.w(TAG, "üîÑ Continuando apenas com detec√ß√£o de faces...")
        }
    }

    private fun checkModelExists(): Boolean {
        return try {
            val files = assets.list("") ?: emptyArray()
            files.contains("model.tflite")
        } catch (e: Exception) {
            false
        }
    }

    private fun validateModelFile(): Boolean {
        return try {
            assets.open("model.tflite").use { inputStream ->
                val header = ByteArray(8)
                val bytesRead = inputStream.read(header)

                Log.d(TAG, "üîç Validando arquivo...")
                Log.d(TAG, "   Bytes lidos: $bytesRead")
                Log.d(TAG, "   Header: ${header.joinToString(" ") { "%02X".format(it) }}")

                // Verifica se tem pelo menos 8 bytes
                if (bytesRead < 8) {
                    Log.e(TAG, "‚ùå Arquivo muito pequeno (${bytesRead} bytes)")
                    return false
                }

                // Verifica assinatura TFLite (pode estar em diferentes posi√ß√µes)
                val isValidTFLite = header.sliceArray(0..3).contentEquals(TFLITE_SIGNATURE) ||
                        header.sliceArray(4..7).contentEquals(TFLITE_SIGNATURE)

                if (isValidTFLite) {
                    Log.d(TAG, "‚úÖ Assinatura TFLite v√°lida encontrada!")
                } else {
                    Log.e(TAG, "‚ùå Assinatura TFLite n√£o encontrada")
                    Log.e(TAG, "   Esperado: ${TFLITE_SIGNATURE.joinToString(" ") { "%02X".format(it) }}")
                }

                isValidTFLite
            }
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao validar arquivo", e)
            false
        }
    }

    private fun createDummyModel() {
        Log.d(TAG, "ü§ñ Criando modelo dummy para demonstra√ß√£o...")
        // Aqui voc√™ poderia criar um modelo simples para teste
        // Por enquanto, s√≥ registra que est√° funcionando sem modelo
        showToast("Modo demonstra√ß√£o: apenas detec√ß√£o de faces")
    }

    private fun listAssetsFiles() {
        try {
            val files = assets.list("") ?: emptyArray()
            Log.d(TAG, "üìÅ Arquivos na pasta assets (${files.size}):")

            if (files.isEmpty()) {
                Log.w(TAG, "   üìÇ Pasta vazia!")
            } else {
                files.forEachIndexed { index, file ->
                    val size = try {
                        assets.openFd(file).declaredLength
                    } catch (e: Exception) {
                        -1L
                    }
                    Log.d(TAG, "   ${index + 1}. $file (${if (size >= 0) "${size} bytes" else "tamanho desconhecido"})")
                }
            }

            Log.d(TAG, "üîç Procurando especificamente por model.tflite...")
            val hasModel = files.contains("model.tflite")
            Log.d(TAG, "   model.tflite presente: ${if (hasModel) "‚úÖ SIM" else "‚ùå N√ÉO"}")

        } catch (e: Exception) {
            Log.e(TAG, "Erro ao listar assets", e)
        }
    }

    private fun checkAndExtractModelDimensions(): Boolean {
        return try {
            val interp = interpreter ?: return false

            val inputTensor = interp.getInputTensor(0)
            val outputTensor = interp.getOutputTensor(0)

            val inputShape = inputTensor.shape()
            val outputShape = outputTensor.shape()

            Log.d(TAG, "üìä === DIMENS√ïES DO MODELO ===")
            Log.d(TAG, "Input shape: ${inputShape.contentToString()}")
            Log.d(TAG, "Output shape: ${outputShape.contentToString()}")
            Log.d(TAG, "Input type: ${inputTensor.dataType()}")
            Log.d(TAG, "Output type: ${outputTensor.dataType()}")

            if (inputShape.size >= 4) {
                modelInputHeight = inputShape[1]
                modelInputWidth = inputShape[2]
                val channels = inputShape[3]
                Log.d(TAG, "üìê Entrada: ${modelInputWidth}x${modelInputHeight}x${channels}")
            }

            if (outputShape.size >= 2) {
                modelOutputSize = outputShape[1]
                Log.d(TAG, "üìê Sa√≠da: vetor ${modelOutputSize}D")
            }

            val valid = modelInputWidth > 0 && modelInputHeight > 0 && modelOutputSize > 0
            Log.d(TAG, "‚úÖ Modelo ${if (valid) "V√ÅLIDO" else "INV√ÅLIDO"}")

            valid

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao analisar modelo", e)
            false
        }
    }

    private fun showToast(message: String) {
        runOnUiThread {
            Toast.makeText(this, message, Toast.LENGTH_LONG).show()
        }
    }

    private fun showSuccessScreen() {
        val usuario = intent.getSerializableExtra("usuario") as? FuncionariosLocalModel
        val faceBitmap = currentFaceBitmap
        
        if (faceBitmap != null) {
            // Criar uma vers√£o otimizada para exibi√ß√£o (300x300 para melhor qualidade)
            val displayBitmap = Bitmap.createScaledBitmap(faceBitmap, 300, 300, true)
            
            // Armazenar no TempImageStorage para evitar problema de transa√ß√£o
            TempImageStorage.storeFaceBitmap(displayBitmap)
            
            // Abre a tela de confirma√ß√£o
            FaceRegistrationSuccessActivity.start(this, usuario)
            finish() // Fecha a CameraActivity
        } else {
            // Fallback para toast se n√£o tiver a foto
            showToast("‚úÖ Facial cadastrado com sucesso!")
        }
    }

    private fun startCamera() {
        Log.d(TAG, "üì∑ === INICIANDO C√ÇMERA ===")

        val cameraProviderFuture = ProcessCameraProvider.getInstance(this)
        cameraProviderFuture.addListener({
            val cameraProvider = cameraProviderFuture.get()
            val preview = Preview.Builder().build().also {
                it.setSurfaceProvider(previewView.surfaceProvider)
            }

            imageAnalyzer = ImageAnalysis.Builder()
                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                .setTargetResolution(android.util.Size(640, 480)) // ‚úÖ SIMPLIFICA√á√ÉO: Resolu√ß√£o menor para melhor performance
                .build().also {
                    it.setAnalyzer(ContextCompat.getMainExecutor(this)) { proxy ->
                        processImage(proxy)
                    }
                }

            try {
                cameraProvider.unbindAll()
                cameraProvider.bindToLifecycle(
                    this,
                    CameraSelector.DEFAULT_FRONT_CAMERA,
                    preview,
                    imageAnalyzer
                )
                Log.d(TAG, "‚úÖ C√¢mera ativa!")
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro na c√¢mera", e)
                showToast("Erro na c√¢mera: ${e.message}")
            }
        }, ContextCompat.getMainExecutor(this))
    }

    private fun processImage(imageProxy: ImageProxy) {
        val mediaImage = imageProxy.image
        if (mediaImage != null) {
            val image = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)

            faceDetector.process(image)
                .addOnSuccessListener { faces ->
                    if (faces.isNotEmpty()) {
                        faceDetectionCount++
                        val face = faces[0]

                        Log.d(TAG, "üë§ FACE #$faceDetectionCount detectada!")

                        overlay.setBoundingBox(face.boundingBox, mediaImage.width, mediaImage.height)

                        // ‚úÖ SISTEMA DE ESTABILIZA√á√ÉO: Verificar se a face est√° est√°vel
                        val isFaceStable = checkFaceStability(face.boundingBox)
                        
                        // ‚úÖ Crit√©rios de qualidade da face
                        val faceArea = face.boundingBox.width() * face.boundingBox.height()
                        val screenArea = mediaImage.width * mediaImage.height
                        val faceRatio = faceArea.toFloat() / screenArea.toFloat()
                        
                        val isFaceBigEnough = faceRatio >= 0.03f // Face deve ocupar 3% da tela (mais rigoroso)
                        val isFaceInOval = overlay.isFaceInOval(face.boundingBox)
                        
                        Log.d(TAG, "üìè Face ratio: $faceRatio, Est√°vel: $isFaceStable, Frames est√°veis: $faceStableCount")
                        
                        // ‚úÖ PROCESSAR APENAS QUANDO EST√ÅVEL E BEM POSICIONADA
                        if (!alreadySaved && !isProcessingFace && isFaceBigEnough && isFaceInOval && isFaceStable) {
                            Log.d(TAG, "‚úÖ FACE EST√ÅVEL E BEM POSICIONADA - PROCESSANDO!")
                            isProcessingFace = true
                            processDetectedFace(mediaImage, face.boundingBox)
                            alreadySaved = true
                            showToast("‚úÖ Rosto detectado! Processando...")
                        } else if (!alreadySaved && !isProcessingFace) {
                            // ‚úÖ FEEDBACK DETALHADO PARA O USU√ÅRIO SE POSICIONAR
                            val feedbackMessage = when {
                                !isFaceBigEnough -> "üì∑ Aproxime mais o rosto"
                                !isFaceInOval -> "üì∑ Centre o rosto no oval"
                                !isFaceStable -> "üì∑ Fique parado (${faceStableCount}/${minStableFrames})"
                                else -> "üì∑ Posicione seu rosto no oval"
                            }
                            
                            // Mostrar feedback a cada 3 frames para ser mais responsivo
                            if (faceDetectionCount % 3 == 0) {
                                showToast(feedbackMessage)
                            }
                        }
                    } else {
                        overlay.clear()
                        // Reset da estabiliza√ß√£o quando perde a face
                        if (faceDetectionCount > 0) {
                            Log.d(TAG, "‚ö†Ô∏è Face perdida - resetando estabiliza√ß√£o")
                            resetFaceStability()
                        }
                    }
                    imageProxy.close()
                }
                .addOnFailureListener { e ->
                    Log.e(TAG, "‚ùå Erro na detec√ß√£o", e)
                    imageProxy.close()
                }
        } else {
            imageProxy.close()
        }
    }


    private fun processDetectedFace(mediaImage: android.media.Image, boundingBox: Rect) {
        try {
            Log.d(TAG, "üîÑ === PROCESSANDO FACE SIMPLIFICADO ===")

            val bitmap = toBitmap(mediaImage)
            saveImage(bitmap, "original")

            val faceBmp = cropFace(bitmap, boundingBox)
            saveImage(faceBmp, "face_cropped")

            // ‚úÖ SIMPLIFICA√á√ÉO: Processar diretamente sem verifica√ß√µes complexas
            Log.d(TAG, "‚úÖ Processando face diretamente")
            processFaceWithHelper(faceBmp)

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro no processamento", e)
            showToast("Erro: ${e.message}")
            alreadySaved = false // Reset para permitir nova tentativa
        }
    }
    
    /**
     * ‚úÖ SIMPLIFICA√á√ÉO: Processar face de forma direta
     */
    private fun processFaceWithHelper(faceBmp: Bitmap) {
        CoroutineScope(Dispatchers.IO).launch {
            try {
                Log.d(TAG, "üîÑ === PROCESSANDO FACE COM TENSORFLOW LITE DIRETO ===")
                
                // ‚úÖ USAR TENSORFLOW LITE DIRETAMENTE SEMPRE
                val embedding = generateEmbeddingDirectly(faceBmp)
                
                if (embedding != null && embedding.isNotEmpty()) {
                    Log.d(TAG, "‚úÖ Embedding gerado com TensorFlow Lite!")
                    Log.d(TAG, "üìä Embedding tamanho: ${embedding.size}")
                    Log.d(TAG, "üìä Primeiros 5 valores: ${embedding.take(5).joinToString(", ")}")
                    
                    // Validar embedding antes de salvar
                    if (validateEmbedding(embedding)) {
                        // Salvar a foto do rosto para mostrar na tela de confirma√ß√£o
                        val faceForDisplay = Bitmap.createScaledBitmap(faceBmp, 300, 300, true)
                        currentFaceBitmap = fixImageOrientationDefinitive(faceForDisplay)
                        
                        // Salvar embedding no banco
                        saveFaceToDatabase(embedding)
                    } else {
                        Log.e(TAG, "‚ùå Embedding inv√°lido gerado")
                        withContext(Dispatchers.Main) {
                            showToast("Embedding inv√°lido. Tente novamente.")
                            isProcessingFace = false
                            alreadySaved = false
                        }
                    }
                } else {
                    Log.e(TAG, "‚ùå Falha ao gerar embedding com TensorFlow Lite")
                    withContext(Dispatchers.Main) {
                        showToast("Falha no processamento. Verifique a ilumina√ß√£o.")
                        isProcessingFace = false
                        alreadySaved = false
                    }
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro cr√≠tico no processamento", e)
                withContext(Dispatchers.Main) {
                    showToast("Erro no processamento: ${e.message}")
                    isProcessingFace = false
                    alreadySaved = false
                }
            }
        }
    }
    

    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Verificar qualidade da face
     */
    private fun checkFaceQuality(bitmap: Bitmap): Float {
        try {
            // Verificar resolu√ß√£o m√≠nima
            if (bitmap.width < 100 || bitmap.height < 100) {
                return 0.1f
            }
            
            // Verificar se n√£o est√° muito escuro ou muito claro
            val pixels = IntArray(bitmap.width * bitmap.height)
            bitmap.getPixels(pixels, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)
            
            var totalBrightness = 0f
            var totalContrast = 0f
            
            for (pixel in pixels) {
                val r = (pixel shr 16) and 0xFF
                val g = (pixel shr 8) and 0xFF
                val b = pixel and 0xFF
                
                val brightness = (r + g + b) / 3f / 255f
                totalBrightness += brightness
            }
            
            val avgBrightness = totalBrightness / pixels.size
            
            // Calcular qualidade baseada na luminosidade
            val quality = when {
                avgBrightness < 0.2f -> 0.2f // Muito escuro
                avgBrightness > 0.8f -> 0.3f // Muito claro
                avgBrightness in 0.3f..0.7f -> 0.8f // Boa luminosidade
                else -> 0.5f // Luminosidade aceit√°vel
            }
            
            Log.d(TAG, "üìä Qualidade calculada: $quality (luminosidade: $avgBrightness)")
            return quality
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao verificar qualidade", e)
            return 0.5f // Qualidade m√©dia como fallback
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Melhorar qualidade da face
     */
    private fun improveFaceQuality(bitmap: Bitmap): Bitmap? {
        try {
            // ‚úÖ MELHORIA: Aplicar filtros para melhorar a qualidade
            val improvedBitmap = bitmap.copy(bitmap.config ?: Bitmap.Config.ARGB_8888, true)
            
            // Aplicar filtro de suaviza√ß√£o para reduzir ru√≠do
            val canvas = Canvas(improvedBitmap)
            val paint = Paint().apply {
                isAntiAlias = true
                isFilterBitmap = true
            }
            
            // Desenhar com filtros aplicados
            canvas.drawBitmap(bitmap, 0f, 0f, paint)
            
            // Redimensionar para melhor qualidade se necess√°rio
            val finalBitmap = if (improvedBitmap.width < 200 || improvedBitmap.height < 200) {
                Bitmap.createScaledBitmap(improvedBitmap, 200, 200, true)
            } else {
                improvedBitmap
            }
            
            Log.d(TAG, "‚úÖ Face melhorada: ${bitmap.width}x${bitmap.height} -> ${finalBitmap.width}x${finalBitmap.height}")
            return finalBitmap
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao melhorar qualidade", e)
            return null
        }
    }
    
    /**
     * ‚úÖ SISTEMA DE ESTABILIZA√á√ÉO: Verificar se a face est√° est√°vel
     */
    private fun checkFaceStability(currentPosition: Rect): Boolean {
        val currentTime = System.currentTimeMillis()
        
        // Se √© a primeira detec√ß√£o, inicializar
        if (lastFacePosition == null) {
            lastFacePosition = currentPosition
            faceStableStartTime = currentTime
            faceStableCount = 1
            Log.d(TAG, "üîÑ Iniciando estabiliza√ß√£o da face")
            return false
        }
        
        // Verificar se a posi√ß√£o mudou significativamente
        val positionChanged = kotlin.math.abs(currentPosition.centerX() - lastFacePosition!!.centerX()) > positionTolerance ||
                             kotlin.math.abs(currentPosition.centerY() - lastFacePosition!!.centerY()) > positionTolerance ||
                             kotlin.math.abs(currentPosition.width() - lastFacePosition!!.width()) > positionTolerance ||
                             kotlin.math.abs(currentPosition.height() - lastFacePosition!!.height()) > positionTolerance
        
        if (positionChanged) {
            // Posi√ß√£o mudou - resetar estabiliza√ß√£o
            Log.d(TAG, "üîÑ Face se moveu - resetando estabiliza√ß√£o")
            lastFacePosition = currentPosition
            faceStableStartTime = currentTime
            faceStableCount = 1
            return false
        } else {
            // Posi√ß√£o est√°vel - incrementar contador
            lastFacePosition = currentPosition
            faceStableCount++
            
            // Verificar se atingiu o tempo m√°ximo
            val timeElapsed = currentTime - faceStableStartTime
            if (timeElapsed > maxStableTime) {
                Log.d(TAG, "‚è∞ Tempo m√°ximo de estabiliza√ß√£o atingido - resetando")
                resetFaceStability()
                return false
            }
            
            // Verificar se atingiu frames m√≠nimos
            val isStable = faceStableCount >= minStableFrames
            if (isStable) {
                Log.d(TAG, "‚úÖ Face estabilizada! Frames: $faceStableCount, Tempo: ${timeElapsed}ms")
            }
            
            return isStable
        }
    }
    
    /**
     * ‚úÖ SISTEMA DE ESTABILIZA√á√ÉO: Resetar estabiliza√ß√£o
     */
    private fun resetFaceStability() {
        faceStableCount = 0
        lastFacePosition = null
        faceStableStartTime = 0L
        faceDetectionCount = 0
        Log.d(TAG, "üîÑ Estabiliza√ß√£o resetada")
    }
    
    /**
     * ‚úÖ GERAR EMBEDDING DIRETAMENTE COM TENSORFLOW LITE
     */
    private fun generateEmbeddingDirectly(faceBmp: Bitmap): FloatArray? {
        return try {
            Log.d(TAG, "ü§ñ === GERANDO EMBEDDING COM TENSORFLOW LITE ===")
            
            if (interpreter == null) {
                Log.e(TAG, "‚ùå Interpreter TensorFlow √© nulo!")
                return null
            }
            
            if (!modelLoaded) {
                Log.e(TAG, "‚ùå Modelo n√£o foi carregado corretamente!")
                return null
            }
            
            Log.d(TAG, "‚úÖ Modelo TensorFlow carregado e pronto")
            Log.d(TAG, "üìä Dimens√µes do modelo: ${modelInputWidth}x${modelInputHeight} ‚Üí ${modelOutputSize}")
            
            val resizedBitmap = Bitmap.createScaledBitmap(faceBmp, 160, 160, true)
            Log.d(TAG, "üìê Face redimensionada: ${faceBmp.width}x${faceBmp.height} ‚Üí ${resizedBitmap.width}x${resizedBitmap.height}")
            
            // ‚úÖ CONVERTER PARA TENSOR DE ENTRADA
            val inputTensor = convertBitmapToTensorInput(resizedBitmap)
            Log.d(TAG, "üìä Tensor de entrada criado: ${inputTensor.capacity()} bytes")
            
            // ‚úÖ CRIAR ARRAY DE SA√çDA COM TAMANHO CORRETO
            val output = Array(1) { FloatArray(modelOutputSize) }
            Log.d(TAG, "üìä Array de sa√≠da criado: 1x${modelOutputSize}")
            
            // ‚úÖ EXECUTAR O MODELO TENSORFLOW LITE
            Log.d(TAG, "üöÄ Executando modelo TensorFlow Lite...")
            interpreter?.run(inputTensor, output)
            
            val embedding = output[0]
            Log.d(TAG, "‚úÖ Modelo executado com sucesso!")
            
            // ‚úÖ VERIFICA√á√ÉO IMEDIATA DO EMBEDDING
            Log.d(TAG, "üîç === VERIFICA√á√ÉO DO EMBEDDING GERADO ===")
            Log.d(TAG, "üìä Tamanho do embedding: ${embedding.size} (esperado: $modelOutputSize)")
            Log.d(TAG, "üìä Primeiros 5 valores: ${embedding.take(5).joinToString(", ") { "%.6f".format(it) }}")
            Log.d(TAG, "üìä √öltimos 5 valores: ${embedding.takeLast(5).joinToString(", ") { "%.6f".format(it) }}")
            
            // ‚úÖ VERIFICAR SE N√ÉO S√ÉO TODOS ZEROS
            val allZeros = embedding.all { it == 0f }
            if (allZeros) {
                Log.e(TAG, "‚ùå CR√çTICO: Embedding cont√©m apenas zeros!")
                return null
            }
            
            // ‚úÖ VERIFICAR SE N√ÉO S√ÉO TODOS IGUAIS
            val allSame = embedding.all { it == embedding[0] }
            if (allSame) {
                Log.e(TAG, "‚ùå CR√çTICO: Embedding cont√©m valores id√™nticos!")
                return null
            }
            
            // ‚úÖ CALCULAR ESTAT√çSTICAS B√ÅSICAS
            val min = embedding.minOrNull() ?: 0f
            val max = embedding.maxOrNull() ?: 0f
            val mean = embedding.average().toFloat()
            val variance = embedding.map { (it - mean) * (it - mean) }.average().toFloat()
            
            Log.d(TAG, "üìä Estat√≠sticas do embedding:")
            Log.d(TAG, "   M√≠nimo: $min")
            Log.d(TAG, "   M√°ximo: $max")
            Log.d(TAG, "   M√©dia: $mean")
            Log.d(TAG, "   Vari√¢ncia: $variance")
            
            // ‚úÖ VERIFICAR SE OS VALORES FAZEM SENTIDO
            if (variance < 0.0001f) {
                Log.e(TAG, "‚ùå CR√çTICO: Vari√¢ncia muito baixa - embedding inv√°lido!")
                return null
            }
            
            Log.d(TAG, "‚úÖ Embedding v√°lido e pronto para salvar!")
            
            // Limpar bitmap tempor√°rio
            if (resizedBitmap != faceBmp) {
                resizedBitmap.recycle()
            }
            
            embedding
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro cr√≠tico ao gerar embedding: ${e.message}", e)
            e.printStackTrace()
            null
        }
    }
    
    /**
     * ‚úÖ VALIDAR EMBEDDING GERADO
     */
    private fun validateEmbedding(embedding: FloatArray): Boolean {
        try {
            Log.d(TAG, "üîç === VALIDANDO EMBEDDING ===")
            
            // Verificar se n√£o est√° vazio
            if (embedding.isEmpty()) {
                Log.e(TAG, "‚ùå Embedding vazio")
                return false
            }
            
            // Verificar se tem o tamanho esperado
            if (embedding.size != modelOutputSize) {
                Log.e(TAG, "‚ùå Tamanho incorreto: ${embedding.size} (esperado: $modelOutputSize)")
                return false
            }
            
            // Verificar se n√£o tem valores inv√°lidos
            val hasNaN = embedding.any { it.isNaN() }
            val hasInf = embedding.any { it.isInfinite() }
            
            if (hasNaN) {
                Log.e(TAG, "‚ùå Embedding cont√©m valores NaN")
                return false
            }
            
            if (hasInf) {
                Log.e(TAG, "‚ùå Embedding cont√©m valores infinitos")
                return false
            }
            
            // Verificar se n√£o s√£o todos zeros
            val allZeros = embedding.all { it == 0f }
            if (allZeros) {
                Log.e(TAG, "‚ùå Embedding cont√©m apenas zeros")
                return false
            }
            
            // Verificar vari√¢ncia m√≠nima
            val mean = embedding.average().toFloat()
            val variance = embedding.map { (it - mean) * (it - mean) }.average().toFloat()
            
            if (variance < 0.001f) {
                Log.e(TAG, "‚ùå Embedding tem vari√¢ncia muito baixa: $variance")
                return false
            }
            
            // Calcular magnitude
            val magnitude = kotlin.math.sqrt(embedding.map { it * it }.sum())
            
            if (magnitude < 0.1f) {
                Log.e(TAG, "‚ùå Embedding tem magnitude muito baixa: $magnitude")
                return false
            }
            
            Log.d(TAG, "‚úÖ Embedding v√°lido!")
            Log.d(TAG, "üìä Vari√¢ncia: $variance")
            Log.d(TAG, "üìä Magnitude: $magnitude")
            Log.d(TAG, "üìä M√©dia: $mean")
            
            return true
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro na valida√ß√£o: ${e.message}", e)
            return false
        }
    }

    private fun saveFaceToDatabase(embedding: FloatArray) {
        try {
            Log.d(TAG, "üíæ === SALVANDO FACE NO BANCO ===")
            
            val usuario = intent.getSerializableExtra("usuario") as? FuncionariosLocalModel
            
            if (usuario == null) {
                Log.e(TAG, "‚ùå Usuario nulo - n√£o foi poss√≠vel salvar o vetor facial.")
                showToast("Erro: usu√°rio n√£o encontrado.")
                return
            }
            
            Log.d(TAG, "üë§ Usu√°rio: ${usuario.nome} (${usuario.codigo})")
            Log.d(TAG, "üìä Embedding tamanho: ${embedding.size}")
            Log.d(TAG, "üìä Primeiros 3 valores: ${embedding.take(3).joinToString(", ")}")
            
            // Validar embedding antes de salvar
            if (embedding.isEmpty()) {
                Log.e(TAG, "‚ùå Embedding vazio!")
                showToast("Erro: embedding facial inv√°lido")
                return
            }
            
            CoroutineScope(Dispatchers.IO).launch {
                try {
                    val dao = AppDatabase.getInstance(applicationContext).faceDao()
                    
                    // ‚úÖ SEGURAN√áA: Verificar se j√° existe face para este funcion√°rio ESPEC√çFICO
                    val existingFace = dao.getByFuncionarioId(usuario.codigo)
                    if (existingFace != null) {
                        Log.d(TAG, "üîÑ Face existente encontrada para ${usuario.nome} (${usuario.codigo}) - atualizando...")
                        
                        // ‚úÖ VALIDAR SE A FACE EXISTENTE √â V√ÅLIDA ANTES DE REMOVER
                        val validator = com.example.iface_offilne.helpers.EmbeddingValidator(this@CameraActivity)
                        val faceValidation = validator.validateSingleEmbedding(existingFace)
                        
                        if (faceValidation.isValid) {
                            Log.d(TAG, "‚úÖ Face existente √© v√°lida - substituindo...")
                            dao.deleteByFuncionarioId(usuario.codigo)
                            Log.d(TAG, "üóëÔ∏è Face antiga deletada para funcion√°rio ${usuario.codigo}")
                        } else {
                            Log.w(TAG, "‚ö†Ô∏è Face existente √© inv√°lida - removendo e recadastrando...")
                            dao.deleteByFuncionarioId(usuario.codigo)
                            Log.d(TAG, "üóëÔ∏è Face inv√°lida removida para funcion√°rio ${usuario.codigo}")
                        }
                    } else {
                        Log.d(TAG, "‚ú® Primeira face para o funcion√°rio ${usuario.nome} (${usuario.codigo})")
                    }
                    
                    // Converter embedding para string
                    val embeddingString = embedding.joinToString(",")
                    Log.d(TAG, "üìù === SALVANDO EMBEDDING NO BANCO ===")
                    Log.d(TAG, "üìù Embedding string tamanho: ${embeddingString.length} caracteres")
                    Log.d(TAG, "üìù Embedding valores (primeiros 50 chars): ${embeddingString.take(50)}...")
                    Log.d(TAG, "üìù Embedding array tamanho: ${embedding.size}")
                    Log.d(TAG, "üìù Embedding primeiros 3: ${embedding.take(3).joinToString(", ") { "%.6f".format(it) }}")
                    Log.d(TAG, "üìù Embedding √∫ltimos 3: ${embedding.takeLast(3).joinToString(", ") { "%.6f".format(it) }}")
                    
                    // Criar nova face
                    val faceEntity = FaceEntity(
                        id = 0, // Deixar o Room gerar o ID
                        funcionarioId = usuario.codigo,
                        embedding = embeddingString,
                        synced = true
                    )
                    
                    // Inserir nova face
                    dao.insert(faceEntity)
                    
                    // Verificar se foi salvo corretamente
                    val savedFace = dao.getByFuncionarioId(usuario.codigo)
                    if (savedFace != null) {
                        Log.d(TAG, "‚úÖ Face salva com sucesso!")
                        Log.d(TAG, "   ID: ${savedFace.id}")
                        Log.d(TAG, "   Funcion√°rio: ${savedFace.funcionarioId}")
                        Log.d(TAG, "   Embedding tamanho: ${savedFace.embedding.split(",").size}")
                        Log.d(TAG, "   Sincronizado: ${savedFace.synced}")
                        
                        // Mostrar tela de confirma√ß√£o na thread principal
                        withContext(Dispatchers.Main) {
                            showSuccessScreen()
                        }
                    } else {
                        Log.e(TAG, "‚ùå Face n√£o foi encontrada ap√≥s salvar!")
                        withContext(Dispatchers.Main) {
                            showToast("Erro: face n√£o foi salva corretamente")
                        }
                    }
                    
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao salvar face: ${e.message}", e)
                    withContext(Dispatchers.Main) {
                        showToast("Erro ao salvar face: ${e.message}")
                    }
                }
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro geral ao salvar face", e)
            showToast("Erro ao salvar face: ${e.message}")
        }
    }


    private fun convertBitmapToTensorInput(bitmap: Bitmap): ByteBuffer {
        try {
            val inputSize = 160 // ‚úÖ CORRIGIDO: Usar 160x160 como esperado pelo modelo
            Log.d(TAG, "üîß Preparando tensor para entrada ${inputSize}x${inputSize}")
            
            if (bitmap.isRecycled) {
                throw IllegalStateException("Bitmap foi reciclado")
            }
            
            // Alocar buffer com tamanho correto para float32
            val byteBuffer = ByteBuffer.allocateDirect(4 * inputSize * inputSize * 3)
            byteBuffer.order(ByteOrder.nativeOrder())

            val resizedBitmap = if (bitmap.width != inputSize || bitmap.height != inputSize) {
                Log.d(TAG, "üîß Redimensionando bitmap de ${bitmap.width}x${bitmap.height} para ${inputSize}x${inputSize}")
                Bitmap.createScaledBitmap(bitmap, inputSize, inputSize, true)
            } else {
                bitmap
            }
            
            val intValues = IntArray(inputSize * inputSize)
            resizedBitmap.getPixels(intValues, 0, inputSize, 0, 0, inputSize, inputSize)
            Log.d(TAG, "‚úÖ Pixels extra√≠dos: ${intValues.size} pixels")

            var pixelCount = 0
            for (pixel in intValues) {
                // Normalizar para [-1, 1] como esperado pelo modelo MobileFaceNet
                val r = ((pixel shr 16) and 0xFF) / 127.5f - 1.0f
                val g = ((pixel shr 8) and 0xFF) / 127.5f - 1.0f
                val b = (pixel and 0xFF) / 127.5f - 1.0f

                byteBuffer.putFloat(r)
                byteBuffer.putFloat(g)
                byteBuffer.putFloat(b)
                pixelCount++
            }
            
            Log.d(TAG, "‚úÖ Tensor preenchido com $pixelCount pixels")
            
            // Limpar bitmap tempor√°rio se foi criado
            if (resizedBitmap != bitmap) {
                resizedBitmap.recycle()
            }

            return byteBuffer
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro em convertBitmapToTensorInput", e)
            throw e
        }
    }

    private fun saveImage(bitmap: Bitmap, prefix: String) {
        try {
            val timestamp = SimpleDateFormat("yyyyMMdd_HHmmss", Locale.getDefault()).format(Date())
            val filename = "${prefix}_${timestamp}.jpg"

            val picturesDir = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_PICTURES)
            val appDir = File(picturesDir, "FaceApp")
            appDir.mkdirs()
            val file = File(appDir, filename)

            FileOutputStream(file).use { out ->
                bitmap.compress(Bitmap.CompressFormat.JPEG, 90, out)
            }

            Log.d(TAG, "üíæ Salvo: ${file.name}")

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao salvar", e)
        }
    }

    private fun allPermissionsGranted() = REQUIRED_PERMISSIONS.all {
        ContextCompat.checkSelfPermission(baseContext, it) == PackageManager.PERMISSION_GRANTED
    }

    @Throws(IOException::class)
    private fun loadModelFile(fileName: String): ByteBuffer {
        return assets.openFd(fileName).use { fileDescriptor ->
            FileInputStream(fileDescriptor.fileDescriptor).use { inputStream ->
                val fileChannel = inputStream.channel
                val startOffset = fileDescriptor.startOffset
                val declaredLength = fileDescriptor.declaredLength

                fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
            }
        }
    }

    /**
     * üîç TESTE DE CONEX√ÉO COM O BANCO DE DADOS
     */
    private fun testDatabaseConnection() {
        Log.d(TAG, "üîç === TESTANDO CONEX√ÉO COM BANCO ===")
        
        CoroutineScope(Dispatchers.IO).launch {
            try {
                val dao = AppDatabase.getInstance(applicationContext).faceDao()
                val allFaces = dao.getAllFaces()
                
                Log.d(TAG, "üìä Total de faces no banco: ${allFaces.size}")
                
                val usuario = intent.getSerializableExtra("usuario") as? FuncionariosLocalModel
                if (usuario != null) {
                    Log.d(TAG, "üë§ Verificando face para usu√°rio: ${usuario.nome} (${usuario.codigo})")
                    
                    val existingFace = dao.getByFuncionarioId(usuario.codigo)
                    if (existingFace != null) {
                        Log.d(TAG, "‚úÖ Face existente encontrada:")
                        Log.d(TAG, "   ID: ${existingFace.id}")
                        Log.d(TAG, "   Embedding tamanho: ${existingFace.embedding.split(",").size}")
                        Log.d(TAG, "   Sincronizado: ${existingFace.synced}")
                    } else {
                        Log.d(TAG, "üìù Nenhuma face encontrada para este usu√°rio")
                    }
                } else {
                    Log.w(TAG, "‚ö†Ô∏è Usu√°rio n√£o informado no intent")
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro ao testar banco de dados", e)
            }
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Detectar qualidade da c√¢mera e ajustar par√¢metros
     */
    private fun detectCameraQuality() {
        Log.d(TAG, "üì∑ === DETECTANDO QUALIDADE DA C√ÇMERA ===")
        
        try {
            val cameraManager = getSystemService(CAMERA_SERVICE) as android.hardware.camera2.CameraManager
            val cameraIds = cameraManager.cameraIdList
            
            for (cameraId in cameraIds) {
                val characteristics = cameraManager.getCameraCharacteristics(cameraId)
                val facing = characteristics.get(android.hardware.camera2.CameraCharacteristics.LENS_FACING)
                
                // Verificar apenas c√¢mera frontal
                if (facing == android.hardware.camera2.CameraCharacteristics.LENS_FACING_FRONT) {
                    val sensorSize = characteristics.get(android.hardware.camera2.CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE)
                    
                    Log.d(TAG, "üì± C√¢mera frontal encontrada:")
                    Log.d(TAG, "   ID: $cameraId")
                    
                    if (sensorSize != null) {
                        Log.d(TAG, "   Sensor: ${sensorSize.width}x${sensorSize.height}")
                        
                        // Classificar qualidade baseada no sensor
                        val sensorPixels = sensorSize.width * sensorSize.height
                        val quality = when {
                            sensorPixels >= 8000000 -> "ALTA" // 8MP+
                            sensorPixels >= 5000000 -> "M√âDIA" // 5MP+
                            sensorPixels >= 2000000 -> "BAIXA" // 2MP+
                            else -> "MUITO BAIXA"
                        }
                        
                        Log.d(TAG, "   Qualidade estimada: $quality (${sensorPixels/1000000}MP)")
                        
                        // ‚úÖ AJUSTAR PAR√ÇMETROS BASEADO NA QUALIDADE
                        adjustParametersForQuality(quality)
                    }
                    
                    break // S√≥ precisamos da c√¢mera frontal
                }
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao detectar qualidade da c√¢mera", e)
            // Usar configura√ß√£o padr√£o
            adjustParametersForQuality("M√âDIA")
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Validar embeddings existentes
     */
    private fun validateExistingEmbeddings() {
        Log.d(TAG, "üîç === VALIDANDO EMBEDDINGS EXISTENTES ===")
        
        CoroutineScope(Dispatchers.IO).launch {
            try {
                val validator = com.example.iface_offilne.helpers.EmbeddingValidator(this@CameraActivity)
                val report = validator.validateAllEmbeddings()
                
                Log.d(TAG, "üìä === RELAT√ìRIO DE VALIDA√á√ÉO ===")
                Log.d(TAG, "‚úÖ Faces v√°lidas: ${report.validFaces}")
                Log.d(TAG, "‚ùå Faces inv√°lidas: ${report.invalidFaces}")
                
                if (report.invalidFaces > 0) {
                    Log.w(TAG, "‚ö†Ô∏è ENCONTRADAS FACES INV√ÅLIDAS!")
                    Log.w(TAG, "üîß Problemas encontrados:")
                    report.problems.forEach { problem ->
                        Log.w(TAG, "   - $problem")
                    }
                    
                    // ‚úÖ SEGURAN√áA: N√ÉO REMOVER AUTOMATICAMENTE - APENAS LOGAR
                    Log.w(TAG, "üõ°Ô∏è SEGURAN√áA: Faces inv√°lidas detectadas mas N√ÉO removidas automaticamente")
                    Log.w(TAG, "üõ°Ô∏è Use a fun√ß√£o de limpeza manual se necess√°rio")
                    
                    withContext(Dispatchers.Main) {
                        showToast("‚ö†Ô∏è ${report.invalidFaces} faces com problemas detectadas")
                    }
                } else {
                    Log.d(TAG, "‚úÖ Todos os embeddings est√£o v√°lidos!")
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro na valida√ß√£o: ${e.message}", e)
            }
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Ajustar par√¢metros baseado na qualidade da c√¢mera
     */
    private fun adjustParametersForQuality(quality: String) {
        Log.d(TAG, "‚öôÔ∏è === AJUSTANDO PAR√ÇMETROS PARA QUALIDADE: $quality ===")
        
        when (quality) {
            "ALTA" -> {
                // C√¢mera de alta qualidade - par√¢metros mais restritivos
                Log.d(TAG, "üéØ Configura√ß√£o para c√¢mera de ALTA qualidade")
                // Manter configura√ß√µes padr√£o
            }
            "M√âDIA" -> {
                // C√¢mera de qualidade m√©dia - par√¢metros equilibrados
                Log.d(TAG, "‚öñÔ∏è Configura√ß√£o para c√¢mera de M√âDIA qualidade")
                // Ajustes moderados j√° aplicados
            }
            "BAIXA", "MUITO BAIXA" -> {
                // C√¢mera de baixa qualidade - par√¢metros mais tolerantes
                Log.d(TAG, "üîß Configura√ß√£o para c√¢mera de BAIXA qualidade")
                
                // ‚úÖ AJUSTES PARA C√ÇMERAS DE BAIXA QUALIDADE:
                // 1. Reduzir tamanho m√≠nimo da face
                // 2. Aumentar toler√¢ncia do oval
                // 3. Reduzir crit√©rios de estabilidade
                
                showToast("üì∑ Detectada c√¢mera de baixa qualidade - Ajustando configura√ß√µes...")
            }
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        interpreter?.close()
        Log.d(TAG, "üõë App finalizado")
    }

    override fun onRequestPermissionsResult(
        requestCode: Int,
        permissions: Array<String>,
        grantResults: IntArray
    ) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQUEST_CODE_PERMISSIONS) {
            if (allPermissionsGranted()) {
                startCamera()
            } else {
                // Verificar quais permiss√µes foram negadas
                val deniedPermissions = mutableListOf<String>()
                for (i in permissions.indices) {
                    if (grantResults[i] != PackageManager.PERMISSION_GRANTED) {
                        deniedPermissions.add(permissions[i])
                    }
                }
                
                Log.e(TAG, "‚ùå Permiss√µes negadas: ${deniedPermissions.joinToString(", ")}")
                
                                    val message = when {
                        deniedPermissions.contains(Manifest.permission.CAMERA) -> 
                            "‚ùå Permiss√£o de c√¢mera negada!\n\nPara registrar sua face, voc√™ precisa permitir o acesso √† c√¢mera.\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative a c√¢mera."
                        deniedPermissions.contains(Manifest.permission.READ_MEDIA_IMAGES) -> 
                            "‚ùå Permiss√£o de m√≠dia negada!\n\nPara salvar fotos, voc√™ precisa permitir o acesso √†s imagens.\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative 'Fotos e v√≠deos'."
                        deniedPermissions.contains(Manifest.permission.POST_NOTIFICATIONS) -> 
                            "‚ùå Permiss√£o de notifica√ß√£o negada!\n\nPara receber avisos do app, voc√™ precisa permitir notifica√ß√µes.\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative 'Notifica√ß√µes'."
                        deniedPermissions.contains(Manifest.permission.WRITE_EXTERNAL_STORAGE) -> 
                            "‚ùå Permiss√£o de armazenamento negada!\n\nPara salvar fotos, voc√™ precisa permitir o acesso ao armazenamento.\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative 'Armazenamento'."
                        else -> "‚ùå Permiss√µes necess√°rias foram negadas!\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative todas as permiss√µes."
                    }
                
                Toast.makeText(this, message, Toast.LENGTH_LONG).show()
                
                // Aguardar um pouco antes de fechar para o usu√°rio ler a mensagem
                android.os.Handler(android.os.Looper.getMainLooper()).postDelayed({
                    finish()
                }, 3000)
            }
        }
    }
}