package com.example.iface_offilne

import android.Manifest
import android.content.pm.PackageManager
import android.graphics.*
import android.os.Bundle
import android.os.Environment
import android.os.Handler
import android.os.Looper
import android.util.Log
import android.view.View
import android.widget.FrameLayout
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.camera.view.PreviewView
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import com.example.iface_offilne.data.AppDatabase
import com.example.iface_offilne.data.FaceEntity
import com.example.iface_offilne.helpers.AdvancedFaceRecognitionHelper
import com.example.iface_offilne.helpers.Helpers
import com.example.iface_offilne.helpers.bitmapToFloatArray
import com.example.iface_offilne.helpers.cropFace
import com.example.iface_offilne.helpers.fixImageOrientationDefinitive
import com.example.iface_offilne.helpers.toBitmap
import com.example.iface_offilne.models.FacesModel
import com.example.iface_offilne.models.FuncionariosLocalModel
import com.example.iface_offilne.util.FaceOverlayView
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import org.tensorflow.lite.Interpreter
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.io.IOException
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.channels.FileChannel
import java.text.SimpleDateFormat
import java.util.*

class CameraActivity : AppCompatActivity() {

    private lateinit var previewView: PreviewView
    private lateinit var imageAnalyzer: ImageAnalysis
    private lateinit var overlay: FaceOverlayView

    private var interpreter: Interpreter? = null
    private var modelLoaded = false

    private var modelInputWidth = 112
    private var modelInputHeight = 112
    private var modelOutputSize = 192
    
    // üöÄ NOVO: Helper avan√ßado para reconhecimento facial
    private lateinit var advancedFaceHelper: AdvancedFaceRecognitionHelper

    companion object {
        private const val REQUEST_CODE_PERMISSIONS = 10
        private val REQUIRED_PERMISSIONS = when {
            android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.UPSIDE_DOWN_CAKE -> {
                // Android 14+ (API 34+)
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.READ_MEDIA_IMAGES,
                    Manifest.permission.POST_NOTIFICATIONS
                )
            }
            android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.TIRAMISU -> {
                // Android 13+ (API 33+)
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.READ_MEDIA_IMAGES
                )
            }
            else -> {
                // Android 12 e abaixo
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.WRITE_EXTERNAL_STORAGE,
                    Manifest.permission.READ_EXTERNAL_STORAGE
                )
            }
        }
        private const val TAG = "CameraActivity"

        // Assinatura de arquivo TFLite v√°lido
        private val TFLITE_SIGNATURE = byteArrayOf(0x54, 0x46, 0x4C, 0x33) // "TFL3"
    }

    private var faceDetector = FaceDetection.getClient(
        FaceDetectorOptions.Builder()
            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST) // ‚úÖ SIMPLIFICA√á√ÉO: Modo r√°pido para melhor performance
            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_NONE)
            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_NONE)
            .setMinFaceSize(0.1f) // ‚úÖ SIMPLIFICA√á√ÉO: Face ainda menor para detectar qualquer rosto
            .build()
    )

    private var alreadySaved = false
    private var faceDetectionCount = 0
    private var currentFaceBitmap: Bitmap? = null

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        setupUI()
        Log.d(TAG, "üöÄ === INICIANDO APLICA√á√ÉO ===")

        // üöÄ NOVO: Inicializar helper avan√ßado
        advancedFaceHelper = AdvancedFaceRecognitionHelper(this)
        
        // üîç TESTE: Verificar banco de dados
        testDatabaseConnection()
        
        // ‚úÖ NOVO: Detectar qualidade da c√¢mera e ajustar par√¢metros
        detectCameraQuality()
        
        // Carrega o modelo
        loadTensorFlowModel()

        // Solicita permiss√µes
        Log.d(TAG, "üîê Verificando permiss√µes...")
        Log.d(TAG, "üì± Vers√£o Android: ${android.os.Build.VERSION.SDK_INT}")
        Log.d(TAG, "üìã Permiss√µes necess√°rias: ${REQUIRED_PERMISSIONS.joinToString(", ")}")
        
        if (allPermissionsGranted()) {
            Log.d(TAG, "‚úÖ Todas as permiss√µes j√° concedidas")
            startCamera()
            
            // ‚úÖ SIMPLIFICA√á√ÉO: Instru√ß√µes mais simples e diretas
            Handler(Looper.getMainLooper()).postDelayed({
                showToast("üì∑ Posicione seu rosto na tela\nQualquer posi√ß√£o funciona!")
            }, 2000)
            
            // ‚úÖ NOVO: Debug para verificar se a detec√ß√£o est√° funcionando
            Handler(Looper.getMainLooper()).postDelayed({
                Log.d(TAG, "üîç DEBUG: Verificando se detec√ß√£o est√° ativa...")
                showToast("üîç Sistema de detec√ß√£o ativo")
            }, 5000)
        } else {
            Log.d(TAG, "‚ùå Permiss√µes pendentes - solicitando...")
            // Mostrar mensagem informativa antes de solicitar permiss√µes
            Toast.makeText(this, "üì∑ O app precisa de permiss√£o para c√¢mera e armazenamento para registrar sua face", Toast.LENGTH_LONG).show()
            ActivityCompat.requestPermissions(this, REQUIRED_PERMISSIONS, REQUEST_CODE_PERMISSIONS)
        }
    }

    private fun setupUI() {
        previewView = PreviewView(this).apply { id = View.generateViewId() }
        overlay = FaceOverlayView(this).apply { id = View.generateViewId() }

        val container = FrameLayout(this).apply {
            layoutParams = FrameLayout.LayoutParams(
                FrameLayout.LayoutParams.MATCH_PARENT,
                FrameLayout.LayoutParams.MATCH_PARENT
            )
            addView(previewView)
        }
        container.addView(overlay)
        setContentView(container)
    }

    private fun loadTensorFlowModel() {
        try {
            Log.d(TAG, "üìÇ === VERIFICA√á√ÉO DO MODELO ===")
            listAssetsFiles()

            // Verifica se o arquivo existe
            if (!checkModelExists()) {
                Log.w(TAG, "‚ö†Ô∏è  Arquivo model.tflite n√£o encontrado")
                createDummyModel()
                showToast("Funcionando sem modelo (apenas detec√ß√£o)")
                return
            }

            // Valida o arquivo
            if (!validateModelFile()) {
                Log.e(TAG, "‚ùå Arquivo model.tflite √© inv√°lido!")
                showToast("Arquivo model.tflite corrompido ou inv√°lido")
                return
            }

            // Tenta carregar
            val buffer = loadModelFile("model.tflite")
            Log.d(TAG, "‚úÖ Buffer carregado! Tamanho: ${buffer.capacity()} bytes")

            // Cria interpretador
            val options = Interpreter.Options().apply {
                setNumThreads(2)
                setUseNNAPI(false)
            }

            interpreter = Interpreter(buffer, options)
            interpreter?.allocateTensors()

            Log.d(TAG, "‚úÖ Interpretador criado e tensores alocados!")

            if (checkAndExtractModelDimensions()) {
                modelLoaded = true
                showToast("‚úÖ Modelo TensorFlow carregado!")
                Log.d(TAG, "üéØ Modelo pronto para uso!")
            } else {
                throw Exception("Dimens√µes do modelo inv√°lidas")
            }

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao carregar modelo: ${e.javaClass.simpleName}", e)

            when {
                e.message?.contains("flatbuffer") == true -> {
                    Log.e(TAG, "üí° DIAGN√ìSTICO: Arquivo n√£o √© um modelo TFLite v√°lido")
                    showToast("‚ùå Arquivo n√£o √© um modelo TensorFlow Lite v√°lido")
                }
                e.message?.contains("not found") == true -> {
                    Log.e(TAG, "üí° DIAGN√ìSTICO: Arquivo model.tflite n√£o encontrado")
                    showToast("‚ö†Ô∏è  Arquivo model.tflite n√£o encontrado")
                }
                else -> {
                    Log.e(TAG, "üí° DIAGN√ìSTICO: Erro desconhecido no modelo")
                    showToast("‚ùå Erro no modelo: ${e.message}")
                }
            }

            interpreter?.close()
            interpreter = null
            modelLoaded = false

            // Funciona sem modelo
            Log.w(TAG, "üîÑ Continuando apenas com detec√ß√£o de faces...")
        }
    }

    private fun checkModelExists(): Boolean {
        return try {
            val files = assets.list("") ?: emptyArray()
            files.contains("model.tflite")
        } catch (e: Exception) {
            false
        }
    }

    private fun validateModelFile(): Boolean {
        return try {
            assets.open("model.tflite").use { inputStream ->
                val header = ByteArray(8)
                val bytesRead = inputStream.read(header)

                Log.d(TAG, "üîç Validando arquivo...")
                Log.d(TAG, "   Bytes lidos: $bytesRead")
                Log.d(TAG, "   Header: ${header.joinToString(" ") { "%02X".format(it) }}")

                // Verifica se tem pelo menos 8 bytes
                if (bytesRead < 8) {
                    Log.e(TAG, "‚ùå Arquivo muito pequeno (${bytesRead} bytes)")
                    return false
                }

                // Verifica assinatura TFLite (pode estar em diferentes posi√ß√µes)
                val isValidTFLite = header.sliceArray(0..3).contentEquals(TFLITE_SIGNATURE) ||
                        header.sliceArray(4..7).contentEquals(TFLITE_SIGNATURE)

                if (isValidTFLite) {
                    Log.d(TAG, "‚úÖ Assinatura TFLite v√°lida encontrada!")
                } else {
                    Log.e(TAG, "‚ùå Assinatura TFLite n√£o encontrada")
                    Log.e(TAG, "   Esperado: ${TFLITE_SIGNATURE.joinToString(" ") { "%02X".format(it) }}")
                }

                isValidTFLite
            }
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao validar arquivo", e)
            false
        }
    }

    private fun createDummyModel() {
        Log.d(TAG, "ü§ñ Criando modelo dummy para demonstra√ß√£o...")
        // Aqui voc√™ poderia criar um modelo simples para teste
        // Por enquanto, s√≥ registra que est√° funcionando sem modelo
        showToast("Modo demonstra√ß√£o: apenas detec√ß√£o de faces")
    }

    private fun listAssetsFiles() {
        try {
            val files = assets.list("") ?: emptyArray()
            Log.d(TAG, "üìÅ Arquivos na pasta assets (${files.size}):")

            if (files.isEmpty()) {
                Log.w(TAG, "   üìÇ Pasta vazia!")
            } else {
                files.forEachIndexed { index, file ->
                    val size = try {
                        assets.openFd(file).declaredLength
                    } catch (e: Exception) {
                        -1L
                    }
                    Log.d(TAG, "   ${index + 1}. $file (${if (size >= 0) "${size} bytes" else "tamanho desconhecido"})")
                }
            }

            Log.d(TAG, "üîç Procurando especificamente por model.tflite...")
            val hasModel = files.contains("model.tflite")
            Log.d(TAG, "   model.tflite presente: ${if (hasModel) "‚úÖ SIM" else "‚ùå N√ÉO"}")

        } catch (e: Exception) {
            Log.e(TAG, "Erro ao listar assets", e)
        }
    }

    private fun checkAndExtractModelDimensions(): Boolean {
        return try {
            val interp = interpreter ?: return false

            val inputTensor = interp.getInputTensor(0)
            val outputTensor = interp.getOutputTensor(0)

            val inputShape = inputTensor.shape()
            val outputShape = outputTensor.shape()

            Log.d(TAG, "üìä === DIMENS√ïES DO MODELO ===")
            Log.d(TAG, "Input shape: ${inputShape.contentToString()}")
            Log.d(TAG, "Output shape: ${outputShape.contentToString()}")
            Log.d(TAG, "Input type: ${inputTensor.dataType()}")
            Log.d(TAG, "Output type: ${outputTensor.dataType()}")

            if (inputShape.size >= 4) {
                modelInputHeight = inputShape[1]
                modelInputWidth = inputShape[2]
                val channels = inputShape[3]
                Log.d(TAG, "üìê Entrada: ${modelInputWidth}x${modelInputHeight}x${channels}")
            }

            if (outputShape.size >= 2) {
                modelOutputSize = outputShape[1]
                Log.d(TAG, "üìê Sa√≠da: vetor ${modelOutputSize}D")
            }

            val valid = modelInputWidth > 0 && modelInputHeight > 0 && modelOutputSize > 0
            Log.d(TAG, "‚úÖ Modelo ${if (valid) "V√ÅLIDO" else "INV√ÅLIDO"}")

            valid

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao analisar modelo", e)
            false
        }
    }

    private fun showToast(message: String) {
        runOnUiThread {
            Toast.makeText(this, message, Toast.LENGTH_LONG).show()
        }
    }

    private fun showSuccessScreen() {
        val usuario = intent.getSerializableExtra("usuario") as? FuncionariosLocalModel
        val faceBitmap = currentFaceBitmap
        
        if (faceBitmap != null) {
            // Criar uma vers√£o otimizada para exibi√ß√£o (300x300 para melhor qualidade)
            val displayBitmap = Bitmap.createScaledBitmap(faceBitmap, 300, 300, true)
            
            // Armazenar no TempImageStorage para evitar problema de transa√ß√£o
            TempImageStorage.storeFaceBitmap(displayBitmap)
            
            // Abre a tela de confirma√ß√£o
            FaceRegistrationSuccessActivity.start(this, usuario)
            finish() // Fecha a CameraActivity
        } else {
            // Fallback para toast se n√£o tiver a foto
            showToast("‚úÖ Facial cadastrado com sucesso!")
        }
    }

    private fun startCamera() {
        Log.d(TAG, "üì∑ === INICIANDO C√ÇMERA ===")

        val cameraProviderFuture = ProcessCameraProvider.getInstance(this)
        cameraProviderFuture.addListener({
            val cameraProvider = cameraProviderFuture.get()
            val preview = Preview.Builder().build().also {
                it.setSurfaceProvider(previewView.surfaceProvider)
            }

            imageAnalyzer = ImageAnalysis.Builder()
                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                .setTargetResolution(android.util.Size(640, 480)) // ‚úÖ SIMPLIFICA√á√ÉO: Resolu√ß√£o menor para melhor performance
                .build().also {
                    it.setAnalyzer(ContextCompat.getMainExecutor(this)) { proxy ->
                        processImage(proxy)
                    }
                }

            try {
                cameraProvider.unbindAll()
                cameraProvider.bindToLifecycle(
                    this,
                    CameraSelector.DEFAULT_FRONT_CAMERA,
                    preview,
                    imageAnalyzer
                )
                Log.d(TAG, "‚úÖ C√¢mera ativa!")
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro na c√¢mera", e)
                showToast("Erro na c√¢mera: ${e.message}")
            }
        }, ContextCompat.getMainExecutor(this))
    }

    private fun processImage(imageProxy: ImageProxy) {
        val mediaImage = imageProxy.image
        if (mediaImage != null) {
            val image = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)

            faceDetector.process(image)
                .addOnSuccessListener { faces ->
                    if (faces.isNotEmpty()) {
                        faceDetectionCount++
                        val face = faces[0]

                        Log.d(TAG, "üë§ FACE #$faceDetectionCount detectada!")

                        overlay.setBoundingBox(face.boundingBox, mediaImage.width, mediaImage.height)

                        // ‚úÖ SIMPLIFICA√á√ÉO: Crit√©rios muito mais simples e tolerantes
                        val faceArea = face.boundingBox.width() * face.boundingBox.height()
                        val screenArea = mediaImage.width * mediaImage.height
                        val faceRatio = faceArea.toFloat() / screenArea.toFloat()
                        
                        Log.d(TAG, "üìè Face ratio: $faceRatio")
                        
                        // ‚úÖ SIMPLIFICA√á√ÉO: Crit√©rios m√≠nimos para funcionar em qualquer aparelho
                        val isFaceBigEnough = faceRatio >= 0.02f // Face deve ocupar apenas 2% da tela (muito tolerante)
                        val isFaceInOval = overlay.isFaceInOval(face.boundingBox)
                        val isFaceStable = faceDetectionCount >= 2 // Apenas 2 detec√ß√µes para estabilizar
                        
                        Log.d(TAG, "üîç Crit√©rios: tamanho=${isFaceBigEnough}, posi√ß√£o=${isFaceInOval}, est√°vel=${isFaceStable}")
                        
                        if (!alreadySaved && isFaceBigEnough && isFaceInOval && isFaceStable) {
                            Log.d(TAG, "‚úÖ FACE DETECTADA - PROCESSANDO IMEDIATAMENTE!")
                            processDetectedFace(mediaImage, face.boundingBox)
                            alreadySaved = true
                            showToast("‚úÖ Rosto detectado! Processando...")
                        } else if (!alreadySaved && isFaceBigEnough && faceDetectionCount >= 5) {
                            // ‚úÖ SIMPLIFICA√á√ÉO: Fallback - processar mesmo fora do oval ap√≥s 5 detec√ß√µes
                            Log.d(TAG, "üîÑ FALLBACK: Processando face fora do oval ap√≥s 5 detec√ß√µes")
                            processDetectedFace(mediaImage, face.boundingBox)
                            alreadySaved = true
                            showToast("‚úÖ Processando face...")
                        } else if (!alreadySaved) {
                            // ‚úÖ SIMPLIFICA√á√ÉO: Feedback mais simples
                            val feedbackMessage = when {
                                !isFaceBigEnough -> "üì∑ Aproxime mais"
                                !isFaceInOval -> "üì∑ Centre no oval"
                                !isFaceStable -> "üì∑ Fique parado"
                                else -> "üì∑ Posicione seu rosto"
                            }
                            
                            // Mostrar feedback a cada 5 frames (mais frequente)
                            if (faceDetectionCount % 5 == 0) {
                                showToast(feedbackMessage)
                            }
                        }
                    } else {
                        overlay.clear()
                        // Reset mais r√°pido
                        if (faceDetectionCount > 0) {
                            Log.d(TAG, "‚ö†Ô∏è Face perdida")
                            faceDetectionCount = 0
                        }
                    }
                    imageProxy.close()
                }
                .addOnFailureListener { e ->
                    Log.e(TAG, "‚ùå Erro na detec√ß√£o", e)
                    imageProxy.close()
                }
        } else {
            imageProxy.close()
        }
    }


    private fun processDetectedFace(mediaImage: android.media.Image, boundingBox: Rect) {
        try {
            Log.d(TAG, "üîÑ === PROCESSANDO FACE SIMPLIFICADO ===")

            val bitmap = toBitmap(mediaImage)
            saveImage(bitmap, "original")

            val faceBmp = cropFace(bitmap, boundingBox)
            saveImage(faceBmp, "face_cropped")

            // ‚úÖ SIMPLIFICA√á√ÉO: Processar diretamente sem verifica√ß√µes complexas
            Log.d(TAG, "‚úÖ Processando face diretamente")
            processFaceWithHelper(faceBmp)

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro no processamento", e)
            showToast("Erro: ${e.message}")
            alreadySaved = false // Reset para permitir nova tentativa
        }
    }
    
    /**
     * ‚úÖ SIMPLIFICA√á√ÉO: Processar face de forma direta
     */
    private fun processFaceWithHelper(faceBmp: Bitmap) {
        CoroutineScope(Dispatchers.IO).launch {
            try {
                Log.d(TAG, "üîÑ Tentando processar face...")
                
                // ‚úÖ SIMPLIFICA√á√ÉO: Tentar processamento direto primeiro
                try {
                    val registrationResult = advancedFaceHelper.registerFaceWithValidation(faceBmp)
                    
                    when (registrationResult) {
                        is AdvancedFaceRecognitionHelper.FaceRegistrationResult.Success -> {
                            Log.d(TAG, "‚úÖ Face validada com sucesso!")
                            
                            // Salvar a foto do rosto para mostrar na tela de confirma√ß√£o
                            val faceForDisplay = Bitmap.createScaledBitmap(faceBmp, 300, 300, true)
                            currentFaceBitmap = fixImageOrientationDefinitive(faceForDisplay)
                            
                            // Salvar embedding no banco
                            saveFaceToDatabase(registrationResult.embedding)
                        }
                        
                        is AdvancedFaceRecognitionHelper.FaceRegistrationResult.Failure -> {
                            Log.w(TAG, "‚ùå Face rejeitada: ${registrationResult.reason}")
                            // ‚úÖ SIMPLIFICA√á√ÉO: Tentar processamento alternativo
                            processFaceAlternative(faceBmp)
                        }
                    }
                    
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro no processamento avan√ßado, tentando alternativa", e)
                    // ‚úÖ SIMPLIFICA√á√ÉO: Fallback para processamento alternativo
                    processFaceAlternative(faceBmp)
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro cr√≠tico no processamento", e)
                withContext(Dispatchers.Main) {
                    showToast("Erro no processamento. Tente novamente.")
                    alreadySaved = false
                }
            }
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Processamento alternativo para c√¢meras de baixa qualidade
     */
    private suspend fun processFaceAlternative(faceBmp: Bitmap) {
        try {
            Log.d(TAG, "üîÑ Tentando processamento alternativo...")
            
            // ‚úÖ SIMPLIFICA√á√ÉO: Processamento mais simples
            val resizedFace = Bitmap.createScaledBitmap(faceBmp, 112, 112, true)
            
            // Tentar gerar embedding diretamente
            val embedding = try {
                val inputTensor = convertBitmapToTensorInput(resizedFace)
                val output = Array(1) { FloatArray(modelOutputSize) }
                
                interpreter?.run(inputTensor, output)
                output[0]
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro ao gerar embedding", e)
                null
            }
            
            if (embedding != null) {
                Log.d(TAG, "‚úÖ Embedding gerado com sucesso!")
                
                // Salvar a foto do rosto
                val faceForDisplay = Bitmap.createScaledBitmap(faceBmp, 300, 300, true)
                currentFaceBitmap = fixImageOrientationDefinitive(faceForDisplay)
                
                // Salvar embedding no banco
                saveFaceToDatabase(embedding)
            } else {
                Log.e(TAG, "‚ùå Falha ao gerar embedding")
                withContext(Dispatchers.Main) {
                    showToast("Falha no processamento. Tente em melhor ilumina√ß√£o.")
                    alreadySaved = false
                }
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro no processamento alternativo", e)
            withContext(Dispatchers.Main) {
                showToast("Erro no processamento alternativo.")
                alreadySaved = false
            }
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Verificar qualidade da face
     */
    private fun checkFaceQuality(bitmap: Bitmap): Float {
        try {
            // Verificar resolu√ß√£o m√≠nima
            if (bitmap.width < 100 || bitmap.height < 100) {
                return 0.1f
            }
            
            // Verificar se n√£o est√° muito escuro ou muito claro
            val pixels = IntArray(bitmap.width * bitmap.height)
            bitmap.getPixels(pixels, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)
            
            var totalBrightness = 0f
            var totalContrast = 0f
            
            for (pixel in pixels) {
                val r = (pixel shr 16) and 0xFF
                val g = (pixel shr 8) and 0xFF
                val b = pixel and 0xFF
                
                val brightness = (r + g + b) / 3f / 255f
                totalBrightness += brightness
            }
            
            val avgBrightness = totalBrightness / pixels.size
            
            // Calcular qualidade baseada na luminosidade
            val quality = when {
                avgBrightness < 0.2f -> 0.2f // Muito escuro
                avgBrightness > 0.8f -> 0.3f // Muito claro
                avgBrightness in 0.3f..0.7f -> 0.8f // Boa luminosidade
                else -> 0.5f // Luminosidade aceit√°vel
            }
            
            Log.d(TAG, "üìä Qualidade calculada: $quality (luminosidade: $avgBrightness)")
            return quality
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao verificar qualidade", e)
            return 0.5f // Qualidade m√©dia como fallback
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Melhorar qualidade da face
     */
    private fun improveFaceQuality(bitmap: Bitmap): Bitmap? {
        try {
            // ‚úÖ MELHORIA: Aplicar filtros para melhorar a qualidade
            val improvedBitmap = bitmap.copy(bitmap.config ?: Bitmap.Config.ARGB_8888, true)
            
            // Aplicar filtro de suaviza√ß√£o para reduzir ru√≠do
            val canvas = Canvas(improvedBitmap)
            val paint = Paint().apply {
                isAntiAlias = true
                isFilterBitmap = true
            }
            
            // Desenhar com filtros aplicados
            canvas.drawBitmap(bitmap, 0f, 0f, paint)
            
            // Redimensionar para melhor qualidade se necess√°rio
            val finalBitmap = if (improvedBitmap.width < 200 || improvedBitmap.height < 200) {
                Bitmap.createScaledBitmap(improvedBitmap, 200, 200, true)
            } else {
                improvedBitmap
            }
            
            Log.d(TAG, "‚úÖ Face melhorada: ${bitmap.width}x${bitmap.height} -> ${finalBitmap.width}x${finalBitmap.height}")
            return finalBitmap
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao melhorar qualidade", e)
            return null
        }
    }

    private fun saveFaceToDatabase(embedding: FloatArray) {
        try {
            Log.d(TAG, "üíæ === SALVANDO FACE NO BANCO ===")
            
            val usuario = intent.getSerializableExtra("usuario") as? FuncionariosLocalModel
            
            if (usuario == null) {
                Log.e(TAG, "‚ùå Usuario nulo - n√£o foi poss√≠vel salvar o vetor facial.")
                showToast("Erro: usu√°rio n√£o encontrado.")
                return
            }
            
            Log.d(TAG, "üë§ Usu√°rio: ${usuario.nome} (${usuario.codigo})")
            Log.d(TAG, "üìä Embedding tamanho: ${embedding.size}")
            Log.d(TAG, "üìä Primeiros 3 valores: ${embedding.take(3).joinToString(", ")}")
            
            // Validar embedding antes de salvar
            if (embedding.isEmpty()) {
                Log.e(TAG, "‚ùå Embedding vazio!")
                showToast("Erro: embedding facial inv√°lido")
                return
            }
            
            CoroutineScope(Dispatchers.IO).launch {
                try {
                    val dao = AppDatabase.getInstance(applicationContext).faceDao()
                    
                    // Verificar se j√° existe face para este funcion√°rio
                    val existingFace = dao.getByFuncionarioId(usuario.codigo)
                    if (existingFace != null) {
                        Log.d(TAG, "üîÑ Face existente encontrada - atualizando...")
                        dao.deleteByFuncionarioId(usuario.codigo)
                        Log.d(TAG, "üóëÔ∏è Face antiga deletada para funcion√°rio ${usuario.codigo}")
                    } else {
                        Log.d(TAG, "‚ú® Primeira face para o funcion√°rio ${usuario.codigo}")
                    }
                    
                    // Converter embedding para string
                    val embeddingString = embedding.joinToString(",")
                    Log.d(TAG, "üìù Embedding string (primeiros 50 chars): ${embeddingString.take(50)}...")
                    
                    // Criar nova face
                    val faceEntity = FaceEntity(
                        id = 0, // Deixar o Room gerar o ID
                        funcionarioId = usuario.codigo,
                        embedding = embeddingString,
                        synced = true
                    )
                    
                    // Inserir nova face
                    dao.insert(faceEntity)
                    
                    // Verificar se foi salvo corretamente
                    val savedFace = dao.getByFuncionarioId(usuario.codigo)
                    if (savedFace != null) {
                        Log.d(TAG, "‚úÖ Face salva com sucesso!")
                        Log.d(TAG, "   ID: ${savedFace.id}")
                        Log.d(TAG, "   Funcion√°rio: ${savedFace.funcionarioId}")
                        Log.d(TAG, "   Embedding tamanho: ${savedFace.embedding.split(",").size}")
                        Log.d(TAG, "   Sincronizado: ${savedFace.synced}")
                        
                        // Mostrar tela de confirma√ß√£o na thread principal
                        withContext(Dispatchers.Main) {
                            showSuccessScreen()
                        }
                    } else {
                        Log.e(TAG, "‚ùå Face n√£o foi encontrada ap√≥s salvar!")
                        withContext(Dispatchers.Main) {
                            showToast("Erro: face n√£o foi salva corretamente")
                        }
                    }
                    
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao salvar face: ${e.message}", e)
                    withContext(Dispatchers.Main) {
                        showToast("Erro ao salvar face: ${e.message}")
                    }
                }
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro geral ao salvar face", e)
            showToast("Erro ao salvar face: ${e.message}")
        }
    }


    private fun convertBitmapToTensorInput(bitmap: Bitmap): ByteBuffer {
        try {
            val inputSize = modelInputWidth // 112
            Log.d(TAG, "üîß Preparando tensor para entrada ${inputSize}x${inputSize}")
            
            if (bitmap.isRecycled) {
                throw IllegalStateException("Bitmap foi reciclado")
            }
            
            // Alocar buffer com tamanho correto para float32
            val byteBuffer = ByteBuffer.allocateDirect(4 * inputSize * inputSize * 3)
            byteBuffer.order(ByteOrder.nativeOrder())

            val resizedBitmap = if (bitmap.width != inputSize || bitmap.height != inputSize) {
                Log.d(TAG, "üîß Redimensionando bitmap de ${bitmap.width}x${bitmap.height} para ${inputSize}x${inputSize}")
                Bitmap.createScaledBitmap(bitmap, inputSize, inputSize, true)
            } else {
                bitmap
            }
            
            val intValues = IntArray(inputSize * inputSize)
            resizedBitmap.getPixels(intValues, 0, inputSize, 0, 0, inputSize, inputSize)
            Log.d(TAG, "‚úÖ Pixels extra√≠dos: ${intValues.size} pixels")

            var pixelCount = 0
            for (pixel in intValues) {
                // Normalizar para [-1, 1] como esperado pelo modelo MobileFaceNet
                val r = ((pixel shr 16) and 0xFF) / 127.5f - 1.0f
                val g = ((pixel shr 8) and 0xFF) / 127.5f - 1.0f
                val b = (pixel and 0xFF) / 127.5f - 1.0f

                byteBuffer.putFloat(r)
                byteBuffer.putFloat(g)
                byteBuffer.putFloat(b)
                pixelCount++
            }
            
            Log.d(TAG, "‚úÖ Tensor preenchido com $pixelCount pixels")
            
            // Limpar bitmap tempor√°rio se foi criado
            if (resizedBitmap != bitmap) {
                resizedBitmap.recycle()
            }

            return byteBuffer
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro em convertBitmapToTensorInput", e)
            throw e
        }
    }

    private fun saveImage(bitmap: Bitmap, prefix: String) {
        try {
            val timestamp = SimpleDateFormat("yyyyMMdd_HHmmss", Locale.getDefault()).format(Date())
            val filename = "${prefix}_${timestamp}.jpg"

            val picturesDir = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_PICTURES)
            val appDir = File(picturesDir, "FaceApp")
            appDir.mkdirs()
            val file = File(appDir, filename)

            FileOutputStream(file).use { out ->
                bitmap.compress(Bitmap.CompressFormat.JPEG, 90, out)
            }

            Log.d(TAG, "üíæ Salvo: ${file.name}")

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao salvar", e)
        }
    }

    private fun allPermissionsGranted() = REQUIRED_PERMISSIONS.all {
        ContextCompat.checkSelfPermission(baseContext, it) == PackageManager.PERMISSION_GRANTED
    }

    @Throws(IOException::class)
    private fun loadModelFile(fileName: String): ByteBuffer {
        return assets.openFd(fileName).use { fileDescriptor ->
            FileInputStream(fileDescriptor.fileDescriptor).use { inputStream ->
                val fileChannel = inputStream.channel
                val startOffset = fileDescriptor.startOffset
                val declaredLength = fileDescriptor.declaredLength

                fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
            }
        }
    }

    /**
     * üîç TESTE DE CONEX√ÉO COM O BANCO DE DADOS
     */
    private fun testDatabaseConnection() {
        Log.d(TAG, "üîç === TESTANDO CONEX√ÉO COM BANCO ===")
        
        CoroutineScope(Dispatchers.IO).launch {
            try {
                val dao = AppDatabase.getInstance(applicationContext).faceDao()
                val allFaces = dao.getAllFaces()
                
                Log.d(TAG, "üìä Total de faces no banco: ${allFaces.size}")
                
                val usuario = intent.getSerializableExtra("usuario") as? FuncionariosLocalModel
                if (usuario != null) {
                    Log.d(TAG, "üë§ Verificando face para usu√°rio: ${usuario.nome} (${usuario.codigo})")
                    
                    val existingFace = dao.getByFuncionarioId(usuario.codigo)
                    if (existingFace != null) {
                        Log.d(TAG, "‚úÖ Face existente encontrada:")
                        Log.d(TAG, "   ID: ${existingFace.id}")
                        Log.d(TAG, "   Embedding tamanho: ${existingFace.embedding.split(",").size}")
                        Log.d(TAG, "   Sincronizado: ${existingFace.synced}")
                    } else {
                        Log.d(TAG, "üìù Nenhuma face encontrada para este usu√°rio")
                    }
                } else {
                    Log.w(TAG, "‚ö†Ô∏è Usu√°rio n√£o informado no intent")
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro ao testar banco de dados", e)
            }
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Detectar qualidade da c√¢mera e ajustar par√¢metros
     */
    private fun detectCameraQuality() {
        Log.d(TAG, "üì∑ === DETECTANDO QUALIDADE DA C√ÇMERA ===")
        
        try {
            val cameraManager = getSystemService(CAMERA_SERVICE) as android.hardware.camera2.CameraManager
            val cameraIds = cameraManager.cameraIdList
            
            for (cameraId in cameraIds) {
                val characteristics = cameraManager.getCameraCharacteristics(cameraId)
                val facing = characteristics.get(android.hardware.camera2.CameraCharacteristics.LENS_FACING)
                
                // Verificar apenas c√¢mera frontal
                if (facing == android.hardware.camera2.CameraCharacteristics.LENS_FACING_FRONT) {
                    val sensorSize = characteristics.get(android.hardware.camera2.CameraCharacteristics.SENSOR_INFO_PIXEL_ARRAY_SIZE)
                    
                    Log.d(TAG, "üì± C√¢mera frontal encontrada:")
                    Log.d(TAG, "   ID: $cameraId")
                    
                    if (sensorSize != null) {
                        Log.d(TAG, "   Sensor: ${sensorSize.width}x${sensorSize.height}")
                        
                        // Classificar qualidade baseada no sensor
                        val sensorPixels = sensorSize.width * sensorSize.height
                        val quality = when {
                            sensorPixels >= 8000000 -> "ALTA" // 8MP+
                            sensorPixels >= 5000000 -> "M√âDIA" // 5MP+
                            sensorPixels >= 2000000 -> "BAIXA" // 2MP+
                            else -> "MUITO BAIXA"
                        }
                        
                        Log.d(TAG, "   Qualidade estimada: $quality (${sensorPixels/1000000}MP)")
                        
                        // ‚úÖ AJUSTAR PAR√ÇMETROS BASEADO NA QUALIDADE
                        adjustParametersForQuality(quality)
                    }
                    
                    break // S√≥ precisamos da c√¢mera frontal
                }
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro ao detectar qualidade da c√¢mera", e)
            // Usar configura√ß√£o padr√£o
            adjustParametersForQuality("M√âDIA")
        }
    }
    
    /**
     * ‚úÖ NOVA FUN√á√ÉO: Ajustar par√¢metros baseado na qualidade da c√¢mera
     */
    private fun adjustParametersForQuality(quality: String) {
        Log.d(TAG, "‚öôÔ∏è === AJUSTANDO PAR√ÇMETROS PARA QUALIDADE: $quality ===")
        
        when (quality) {
            "ALTA" -> {
                // C√¢mera de alta qualidade - par√¢metros mais restritivos
                Log.d(TAG, "üéØ Configura√ß√£o para c√¢mera de ALTA qualidade")
                // Manter configura√ß√µes padr√£o
            }
            "M√âDIA" -> {
                // C√¢mera de qualidade m√©dia - par√¢metros equilibrados
                Log.d(TAG, "‚öñÔ∏è Configura√ß√£o para c√¢mera de M√âDIA qualidade")
                // Ajustes moderados j√° aplicados
            }
            "BAIXA", "MUITO BAIXA" -> {
                // C√¢mera de baixa qualidade - par√¢metros mais tolerantes
                Log.d(TAG, "üîß Configura√ß√£o para c√¢mera de BAIXA qualidade")
                
                // ‚úÖ AJUSTES PARA C√ÇMERAS DE BAIXA QUALIDADE:
                // 1. Reduzir tamanho m√≠nimo da face
                // 2. Aumentar toler√¢ncia do oval
                // 3. Reduzir crit√©rios de estabilidade
                
                showToast("üì∑ Detectada c√¢mera de baixa qualidade - Ajustando configura√ß√µes...")
            }
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        interpreter?.close()
        Log.d(TAG, "üõë App finalizado")
    }

    override fun onRequestPermissionsResult(
        requestCode: Int,
        permissions: Array<String>,
        grantResults: IntArray
    ) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQUEST_CODE_PERMISSIONS) {
            if (allPermissionsGranted()) {
                startCamera()
            } else {
                // Verificar quais permiss√µes foram negadas
                val deniedPermissions = mutableListOf<String>()
                for (i in permissions.indices) {
                    if (grantResults[i] != PackageManager.PERMISSION_GRANTED) {
                        deniedPermissions.add(permissions[i])
                    }
                }
                
                Log.e(TAG, "‚ùå Permiss√µes negadas: ${deniedPermissions.joinToString(", ")}")
                
                                    val message = when {
                        deniedPermissions.contains(Manifest.permission.CAMERA) -> 
                            "‚ùå Permiss√£o de c√¢mera negada!\n\nPara registrar sua face, voc√™ precisa permitir o acesso √† c√¢mera.\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative a c√¢mera."
                        deniedPermissions.contains(Manifest.permission.READ_MEDIA_IMAGES) -> 
                            "‚ùå Permiss√£o de m√≠dia negada!\n\nPara salvar fotos, voc√™ precisa permitir o acesso √†s imagens.\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative 'Fotos e v√≠deos'."
                        deniedPermissions.contains(Manifest.permission.POST_NOTIFICATIONS) -> 
                            "‚ùå Permiss√£o de notifica√ß√£o negada!\n\nPara receber avisos do app, voc√™ precisa permitir notifica√ß√µes.\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative 'Notifica√ß√µes'."
                        deniedPermissions.contains(Manifest.permission.WRITE_EXTERNAL_STORAGE) -> 
                            "‚ùå Permiss√£o de armazenamento negada!\n\nPara salvar fotos, voc√™ precisa permitir o acesso ao armazenamento.\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative 'Armazenamento'."
                        else -> "‚ùå Permiss√µes necess√°rias foram negadas!\n\nV√° em Configura√ß√µes > Apps > iFace Offline > Permiss√µes e ative todas as permiss√µes."
                    }
                
                Toast.makeText(this, message, Toast.LENGTH_LONG).show()
                
                // Aguardar um pouco antes de fechar para o usu√°rio ler a mensagem
                android.os.Handler(android.os.Looper.getMainLooper()).postDelayed({
                    finish()
                }, 3000)
            }
        }
    }
}