package com.example.iface_offilne

import android.Manifest
import android.app.AlertDialog
import android.content.Intent
import android.content.pm.PackageManager
import android.graphics.*
import android.os.Bundle
import android.os.Handler
import android.os.Looper
import android.util.Log
import android.view.View
import android.widget.*
import androidx.appcompat.app.AppCompatActivity
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.camera.view.PreviewView
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import com.example.iface_offilne.data.AppDatabase
import com.example.iface_offilne.data.FuncionariosEntity
import com.example.iface_offilne.data.PontosGenericosEntity
import com.example.iface_offilne.service.PontoSincronizacaoService
import com.example.iface_offilne.helpers.FaceRecognitionHelper
import com.example.iface_offilne.helpers.LocationHelper
import com.example.iface_offilne.helpers.bitmapToBase64
import com.example.iface_offilne.helpers.cropFace
import com.example.iface_offilne.helpers.fixImageOrientationDefinitive
import com.example.iface_offilne.helpers.toBitmap
import com.example.iface_offilne.util.FaceOverlayView
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.face.FaceDetection
import com.google.mlkit.vision.face.FaceDetectorOptions
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.channels.FileChannel
import java.text.SimpleDateFormat
import java.util.*

class PontoActivity : AppCompatActivity() {

    private lateinit var previewView: PreviewView
    private lateinit var imageAnalyzer: ImageAnalysis
    private lateinit var overlay: FaceOverlayView
    private lateinit var statusText: TextView
    private lateinit var funcionarioInfo: LinearLayout
    private lateinit var funcionarioNome: TextView
    private lateinit var ultimoPonto: TextView
    private lateinit var tipoPontoRadioGroup: RadioGroup

    private var interpreter: Interpreter? = null
    private var modelLoaded = false
    private var modelInputWidth = 160
    private var modelInputHeight = 160
    private var modelOutputSize = 512

    private var faceRecognitionHelper: FaceRecognitionHelper? = null
    private var locationHelper: LocationHelper? = null
    private var funcionarioReconhecido: FuncionariosEntity? = null
    private var processandoFace = false
    private var currentFaceBitmap: Bitmap? = null
    private var cameraProvider: ProcessCameraProvider? = null
    private var lastProcessingTime = 0L
    private var processingTimeout = 10000L

    private var tensorFlowFallbackMode = false
    private var lastTensorFlowError = 0L
    private var tensorFlowErrorCount = 0
    private val maxTensorFlowErrors = 3

    companion object {
        private const val REQUEST_CODE_PERMISSIONS = 10
        private const val REQUEST_CODE_LOCATION_PERMISSIONS = 20
        private val REQUIRED_PERMISSIONS = when {
            android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.UPSIDE_DOWN_CAKE -> {
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.READ_MEDIA_IMAGES,
                    Manifest.permission.POST_NOTIFICATIONS
                )
            }
            android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.TIRAMISU -> {
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.READ_MEDIA_IMAGES
                )
            }
            else -> {
                arrayOf(
                    Manifest.permission.CAMERA,
                    Manifest.permission.WRITE_EXTERNAL_STORAGE,
                    Manifest.permission.READ_EXTERNAL_STORAGE
                )
            }
        }
        private val LOCATION_PERMISSIONS = arrayOf(
            Manifest.permission.ACCESS_FINE_LOCATION,
            Manifest.permission.ACCESS_COARSE_LOCATION
        )
        private const val TAG = "PontoActivity"
    }

    private var faceDetector = FaceDetection.getClient(
        FaceDetectorOptions.Builder()
            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST)
            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_NONE)
            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_NONE)
            .setMinFaceSize(0.05f) // Detecta faces muito pequenas
            .build()
    )

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_ponto)
        
        Log.d(TAG, "üöÄ === INICIANDO PONTOACTIVITY ===")
        
        try {
            setupUI()
            Log.d(TAG, "‚úÖ UI configurada")
            
            initializeHelpers()
            Log.d(TAG, "‚úÖ Helpers inicializados")
            
            loadTensorFlowModel()
            Log.d(TAG, "‚úÖ Modelo TensorFlow iniciado")
            
            createTestEmployeeIfNeeded()
            Log.d(TAG, "‚úÖ Funcion√°rio de teste verificado")
            
            if (allPermissionsGranted()) {
                Log.d(TAG, "‚úÖ Permiss√µes concedidas")
                if (!allLocationPermissionsGranted()) {
                    Log.d(TAG, "üìç Solicitando permiss√µes de localiza√ß√£o")
                    ActivityCompat.requestPermissions(this, LOCATION_PERMISSIONS, REQUEST_CODE_LOCATION_PERMISSIONS)
                } else {
                    Log.d(TAG, "üìç Permiss√µes de localiza√ß√£o j√° concedidas")
                }
                startCamera()
            } else {
                Log.d(TAG, "üîê Solicitando permiss√µes")
                ActivityCompat.requestPermissions(this, REQUIRED_PERMISSIONS, REQUEST_CODE_PERMISSIONS)
            }
            
            Log.d(TAG, "‚úÖ PontoActivity inicializada com sucesso")
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro cr√≠tico na inicializa√ß√£o", e)
            e.printStackTrace()
            Toast.makeText(this, "‚ùå Erro na inicializa√ß√£o: ${e.message}", Toast.LENGTH_LONG).show()
        }
    }

    private fun setupUI() {
        statusText = findViewById(R.id.statusText)
        previewView = findViewById(R.id.previewView)
        overlay = findViewById(R.id.overlay)
        funcionarioInfo = findViewById(R.id.funcionarioInfo)
        funcionarioNome = findViewById(R.id.funcionarioNome)
        ultimoPonto = findViewById(R.id.ultimoPonto)
        tipoPontoRadioGroup = findViewById(R.id.tipoPontoRadioGroup)
        
        findViewById<Button>(R.id.btnVoltar).setOnClickListener {
            val intent = Intent(this, ConfiguracoesActivity::class.java)
            startActivity(intent)
        }
        
        findViewById<Button>(R.id.btnSair).setOnClickListener {
            onBackPressed()
        }
    }

    private fun initializeHelpers() {
        try {
            Log.d(TAG, "üîß Inicializando helpers...")
            
            // ‚úÖ PROTE√á√ÉO: Inicializar FaceRecognitionHelper
            try {
                faceRecognitionHelper = FaceRecognitionHelper(this)
                Log.d(TAG, "‚úÖ FaceRecognitionHelper inicializado")
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro ao inicializar FaceRecognitionHelper: ${e.message}")
                e.printStackTrace()
            }
            
            // ‚úÖ PROTE√á√ÉO: Inicializar LocationHelper
            try {
                locationHelper = LocationHelper(this)
                Log.d(TAG, "‚úÖ LocationHelper inicializado")
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro ao inicializar LocationHelper: ${e.message}")
                e.printStackTrace()
            }
            
            Log.d(TAG, "‚úÖ Helpers inicializados com sucesso")
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro cr√≠tico ao inicializar helpers", e)
            e.printStackTrace()
        }
    }

    private fun loadTensorFlowModel() {
        Log.d(TAG, "ü§ñ Carregando modelo TensorFlow...")
        CoroutineScope(Dispatchers.IO).launch {
            try {
                // ‚úÖ PROTE√á√ÉO: Verificar se a Activity ainda est√° v√°lida
                if (isFinishing || isDestroyed) {
                    Log.w(TAG, "‚ö†Ô∏è Activity finalizada - cancelando carregamento do modelo")
                    return@launch
                }
                
                // ‚úÖ PROTE√á√ÉO: Limpar interpreter anterior
                try {
                    interpreter?.close()
                    interpreter = null
                    modelLoaded = false
                    Log.d(TAG, "üßπ Interpreter anterior limpo")
                } catch (e: Exception) {
                    Log.w(TAG, "‚ö†Ô∏è Erro ao limpar interpreter anterior: ${e.message}")
                }
                
                val modelFile = try {
                    Log.d(TAG, "üìÅ Tentando abrir modelo do assets...")
                    assets.open("facenet_model.tflite")
                } catch (e: Exception) {
                    Log.w(TAG, "‚ö†Ô∏è Modelo n√£o encontrado em assets, tentando raw resources...")
                    try {
                        resources.openRawResource(R.raw.mobilefacenet)
                    } catch (e2: Exception) {
                        Log.e(TAG, "‚ùå Erro ao abrir modelo: ${e2.message}")
                        throw e2
                    }
                }
                
                Log.d(TAG, "üìÑ Modelo encontrado, lendo bytes...")
                val modelBuffer = modelFile.use { input ->
                    val available = input.available()
                    if (available <= 0 || available > 100 * 1024 * 1024) { // M√°ximo 100MB
                        throw Exception("Tamanho de modelo inv√°lido: $available bytes")
                    }
                    
                    val bytes = ByteArray(available)
                    val bytesRead = input.read(bytes)
                    if (bytesRead != available) {
                        throw Exception("Erro na leitura do modelo: lidos $bytesRead de $available bytes")
                    }
                    
                    Log.d(TAG, "üìä Bytes lidos: ${bytes.size}")
                    
                    try {
                        ByteBuffer.allocateDirect(bytes.size).apply {
                            order(ByteOrder.nativeOrder())
                            put(bytes)
                            rewind()
                        }
                    } catch (e: Exception) {
                        Log.e(TAG, "‚ùå Erro ao alocar buffer do modelo: ${e.message}")
                        throw e
                    }
                }
                
                Log.d(TAG, "‚öôÔ∏è Configurando op√ß√µes do Interpreter...")
                val options = try {
                    Interpreter.Options().apply {
                        setNumThreads(1)
                        setUseNNAPI(false)
                        setAllowFp16PrecisionForFp32(false) // Desabilitar FP16 para evitar problemas
                        setAllowBufferHandleOutput(false) // Desabilitar buffer handle
                    }
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao configurar op√ß√µes: ${e.message}")
                    throw e
                }
                
                Log.d(TAG, "üîß Criando Interpreter...")
                interpreter = try {
                    Interpreter(modelBuffer, options)
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao criar Interpreter: ${e.message}")
                    throw e
                }
                
                // ‚úÖ PROTE√á√ÉO: Verificar se o interpreter foi criado corretamente
                if (interpreter != null) {
                    // ‚úÖ PROTE√á√ÉO: Testar o interpreter com dados dummy
                    try {
                        val currentInterpreter = interpreter
                        if (currentInterpreter != null) {
                            val testInput = ByteBuffer.allocateDirect(4 * modelInputWidth * modelInputHeight * 3)
                            testInput.order(ByteOrder.nativeOrder())
                            val testOutput = Array(1) { FloatArray(modelOutputSize) }
                            
                            currentInterpreter.run(testInput, testOutput)
                            Log.d(TAG, "‚úÖ Teste do interpreter bem-sucedido")
                            
                            modelLoaded = true
                            Log.d(TAG, "‚úÖ Modelo TensorFlow carregado com sucesso")
                        } else {
                            Log.e(TAG, "‚ùå Interpreter √© nulo durante teste")
                            modelLoaded = false
                        }
                    } catch (e: Exception) {
                        Log.e(TAG, "‚ùå Erro no teste do interpreter: ${e.message}")
                        interpreter?.close()
                        interpreter = null
                        modelLoaded = false
                        throw e
                    }
                } else {
                    Log.e(TAG, "‚ùå Interpreter criado mas √© nulo")
                    modelLoaded = false
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Erro ao carregar modelo TensorFlow", e)
                e.printStackTrace()
                modelLoaded = false
                
                // ‚úÖ PROTE√á√ÉO: Limpar recursos em caso de erro
                try {
                    interpreter?.close()
                    interpreter = null
                } catch (closeException: Exception) {
                    Log.e(TAG, "‚ùå Erro ao fechar interpreter: ${closeException.message}")
                }
            }
        }
    }

    private fun startCamera() {
        Log.d(TAG, "üì∑ Iniciando c√¢mera")
        
        // ‚úÖ PROTE√á√ÉO: Verificar se a Activity ainda est√° v√°lida
        if (isFinishing || isDestroyed) {
            Log.w(TAG, "‚ö†Ô∏è Activity finalizada - cancelando inicializa√ß√£o da c√¢mera")
            return
        }
        
        try {
            val cameraProviderFuture = ProcessCameraProvider.getInstance(this)
            cameraProviderFuture.addListener({
                try {
                    // ‚úÖ PROTE√á√ÉO: Verificar novamente se a Activity ainda est√° v√°lida
                    if (isFinishing || isDestroyed) {
                        Log.w(TAG, "‚ö†Ô∏è Activity finalizada durante inicializa√ß√£o da c√¢mera")
                        return@addListener
                    }
                    
                    cameraProvider = cameraProviderFuture.get()
                    Log.d(TAG, "‚úÖ CameraProvider obtido")

                    // ‚úÖ PROTE√á√ÉO: Verificar se previewView est√° inicializado
                    if (!::previewView.isInitialized) {
                        Log.e(TAG, "‚ùå PreviewView n√£o inicializado")
                        return@addListener
                    }

                    val preview = Preview.Builder()
                        .setTargetResolution(android.util.Size(800, 600))
                        .build().also {
                            try {
                                val preview = previewView
                                it.setSurfaceProvider(preview.surfaceProvider)
                                Log.d(TAG, "‚úÖ Preview configurado")
                            } catch (e: Exception) {
                                Log.e(TAG, "‚ùå Erro ao configurar preview: ${e.message}")
                                return@addListener
                            }
                        }

                    imageAnalyzer = ImageAnalysis.Builder()
                        .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                        .setTargetResolution(android.util.Size(640, 480))
                        .build()
                        .also {
                            try {
                                it.setAnalyzer(ContextCompat.getMainExecutor(this)) { imageProxy ->
                                    processImage(imageProxy)
                                }
                                Log.d(TAG, "‚úÖ ImageAnalyzer configurado")
                            } catch (e: Exception) {
                                Log.e(TAG, "‚ùå Erro ao configurar ImageAnalyzer: ${e.message}")
                                return@addListener
                            }
                        }

                    val cameraSelector = CameraSelector.DEFAULT_FRONT_CAMERA
                    Log.d(TAG, "‚úÖ CameraSelector configurado")

                    try {
                        val provider = cameraProvider
                        provider?.unbindAll()
                        Log.d(TAG, "‚úÖ C√¢meras desvinculadas")
                    } catch (e: Exception) {
                        Log.w(TAG, "‚ö†Ô∏è Erro ao desvincular c√¢meras: ${e.message}")
                    }

                    try {
                        val provider = cameraProvider
                        provider?.bindToLifecycle(this, cameraSelector, preview, imageAnalyzer)
                        Log.d(TAG, "‚úÖ C√¢mera vinculada ao lifecycle")
                    } catch (e: Exception) {
                        Log.e(TAG, "‚ùå Erro ao vincular c√¢mera: ${e.message}")
                        return@addListener
                    }
                    
                    Log.d(TAG, "‚úÖ C√¢mera iniciada com sucesso")
                    
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao iniciar c√¢mera", e)
                    e.printStackTrace()
                }
            }, ContextCompat.getMainExecutor(this))
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro cr√≠tico ao obter CameraProvider", e)
            e.printStackTrace()
        }
    }

    private fun processImage(imageProxy: ImageProxy) {
        try {
            // ‚úÖ PROTE√á√ÉO CR√çTICA: Verificar se a Activity ainda est√° v√°lida
            if (isFinishing || isDestroyed) {
                Log.w(TAG, "‚ö†Ô∏è Activity finalizada - fechando imageProxy sem processar")
                try {
                    imageProxy.close()
                } catch (e: Exception) {
                    Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${e.message}")
                }
                return
            }

            // ‚úÖ RESET: Verificar se deve resetar modo fallback
            resetFallbackMode()

            // ‚úÖ PROTE√á√ÉO: Verificar se o faceDetector ainda est√° v√°lido
            if (faceDetector == null) {
                Log.w(TAG, "‚ö†Ô∏è FaceDetector nulo - fechando imageProxy")
                try {
                    imageProxy.close()
                } catch (e: Exception) {
                    Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${e.message}")
                }
                return
            }

            val mediaImage = imageProxy.image
            if (mediaImage != null) {
                Log.d(TAG, "üì∏ Processando imagem: ${mediaImage.width}x${mediaImage.height}")
                
                try {
                    val image = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)
                    Log.d(TAG, "üîÑ Imagem convertida para InputImage")

                    val detector = faceDetector
                    detector.process(image)
                        .addOnSuccessListener { faces ->
                            try {
                                Log.d(TAG, "üë• Faces detectadas: ${faces.size}")
                                
                                if (faces.isNotEmpty()) {
                                    val face = faces[0]
                                    Log.d(TAG, "üéØ Face principal: ${face.boundingBox}")
                                    
                                    // ‚úÖ PROTE√á√ÉO: Verificar se overlay ainda est√° v√°lido
                                    try {
                                        if (!isFinishing && !isDestroyed && ::overlay.isInitialized) {
                                            val overlayView = overlay
                                            overlayView.setBoundingBox(face.boundingBox, mediaImage.width, mediaImage.height)
                                        } else {
                                            Log.w(TAG, "‚ö†Ô∏è Overlay n√£o dispon√≠vel para atualiza√ß√£o")
                                        }
                                    } catch (e: Exception) {
                                        Log.w(TAG, "‚ö†Ô∏è Erro ao atualizar overlay: ${e.message}")
                                    }

                                    val faceArea = face.boundingBox.width() * face.boundingBox.height()
                                    val screenArea = mediaImage.width * mediaImage.height
                                    val faceRatio = faceArea.toFloat() / screenArea.toFloat()
                                    
                                    Log.d(TAG, "üìä Face ratio: $faceRatio")
                                    
                                    // ‚úÖ PROTE√á√ÉO: Verificar se pode processar face
                                    if (!processandoFace && modelLoaded && interpreter != null && !isFinishing && !isDestroyed) {
                                        Log.d(TAG, "‚úÖ INICIANDO RECONHECIMENTO - QUALQUER FACE!")
                                        
                                        processandoFace = true
                                        lastProcessingTime = System.currentTimeMillis()
                                        
                                        // ‚úÖ PROTE√á√ÉO: Atualizar status com verifica√ß√£o
                                        try {
                                            if (!isFinishing && !isDestroyed && ::statusText.isInitialized) {
                                                val status = statusText
                                                status.text = "üîç Reconhecendo..."
                                            } else {
                                                Log.w(TAG, "‚ö†Ô∏è StatusText n√£o dispon√≠vel para atualiza√ß√£o")
                                            }
                                        } catch (e: Exception) {
                                            Log.w(TAG, "‚ö†Ô∏è Erro ao atualizar status: ${e.message}")
                                        }
                                        
                                        // ‚úÖ PROTE√á√ÉO: Converter bitmap com verifica√ß√£o
                                        try {
                                            val bitmap = toBitmap(mediaImage)
                                            Log.d(TAG, "üñºÔ∏è Bitmap convertido: ${bitmap.width}x${bitmap.height}")
                                            
                                            // ‚úÖ PROTE√á√ÉO: Fechar imageProxy antes de processar
                                            try {
                                                imageProxy.close()
                                            } catch (e: Exception) {
                                                Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${e.message}")
                                            }
                                            
                                            processDetectedFace(bitmap, face.boundingBox)
                                        } catch (e: Exception) {
                                            Log.e(TAG, "‚ùå Erro ao converter bitmap", e)
                                            processandoFace = false
                                            try {
                                                imageProxy.close()
                                            } catch (closeException: Exception) {
                                                Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${closeException.message}")
                                            }
                                        }
                                    } else {
                                        Log.d(TAG, "‚è∏Ô∏è N√£o processando face - processandoFace: $processandoFace, modelLoaded: $modelLoaded, interpreter: ${interpreter != null}")
                                        try {
                                            imageProxy.close()
                                        } catch (e: Exception) {
                                            Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${e.message}")
                                        }
                                    }
                                } else {
                                    Log.d(TAG, "üë§ Nenhuma face detectada")
                                    try {
                                        if (!isFinishing && !isDestroyed && ::overlay.isInitialized) {
                                            val overlayView = overlay
                                            overlayView.clear()
                                        }
                                    } catch (e: Exception) {
                                        Log.w(TAG, "‚ö†Ô∏è Erro ao limpar overlay: ${e.message}")
                                    }
                                    try {
                                        imageProxy.close()
                                    } catch (e: Exception) {
                                        Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${e.message}")
                                    }
                                }
                            } catch (e: Exception) {
                                Log.e(TAG, "‚ùå Erro no processamento de faces", e)
                                processandoFace = false
                                try {
                                    imageProxy.close()
                                } catch (closeException: Exception) {
                                    Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${closeException.message}")
                                }
                            }
                        }
                        .addOnFailureListener { e ->
                            Log.e(TAG, "‚ùå Erro na detec√ß√£o de faces", e)
                            processandoFace = false
                            try {
                                imageProxy.close()
                            } catch (closeException: Exception) {
                                Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${closeException.message}")
                            }
                        }
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao criar InputImage", e)
                    try {
                        imageProxy.close()
                    } catch (closeException: Exception) {
                        Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${closeException.message}")
                    }
                }
            } else {
                Log.w(TAG, "‚ö†Ô∏è MediaImage nulo")
                try {
                    imageProxy.close()
                } catch (e: Exception) {
                    Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${e.message}")
                }
            }
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erro cr√≠tico no processImage", e)
            e.printStackTrace()
            processandoFace = false
            try {
                imageProxy.close()
            } catch (closeException: Exception) {
                Log.w(TAG, "‚ö†Ô∏è Erro ao fechar imageProxy: ${closeException.message}")
            }
        }
    }

    private fun processDetectedFace(bitmap: Bitmap, boundingBox: Rect) {
        Log.d(TAG, "üîÑ Processando face detectada")
        
        // ‚úÖ PROTE√á√ÉO CR√çTICA: Verificar se a Activity ainda est√° v√°lida
        if (isFinishing || isDestroyed) {
            Log.w(TAG, "‚ö†Ô∏è Activity finalizada - cancelando processamento de face")
            processandoFace = false
            return
        }
        
        // ‚úÖ PROTE√á√ÉO: Verificar se o bitmap √© v√°lido
        if (bitmap.isRecycled || bitmap.width <= 0 || bitmap.height <= 0) {
            Log.e(TAG, "‚ùå Bitmap inv√°lido - reciclado: ${bitmap.isRecycled}, dimens√µes: ${bitmap.width}x${bitmap.height}")
            processandoFace = false
            return
        }
        
        // ‚úÖ PROTE√á√ÉO: Verificar se o boundingBox √© v√°lido
        if (boundingBox.isEmpty || boundingBox.width() <= 0 || boundingBox.height() <= 0) {
            Log.e(TAG, "‚ùå BoundingBox inv√°lido: $boundingBox")
            processandoFace = false
            return
        }
        
        // ‚úÖ FALLBACK: Verificar se deve usar modo fallback
        if (tensorFlowFallbackMode) {
            Log.d(TAG, "üîÑ Usando modo fallback - TensorFlow desabilitado")
            CoroutineScope(Dispatchers.IO).launch {
                processFaceWithFallback(bitmap, boundingBox)
            }
            return
        }
        
        Log.d(TAG, "‚úÖ Valida√ß√µes passadas - iniciando processamento")

        CoroutineScope(Dispatchers.IO).launch {
            try {
                // ‚úÖ PROTE√á√ÉO: Verificar novamente se a Activity ainda est√° v√°lida
                if (isFinishing || isDestroyed) {
                    Log.w(TAG, "‚ö†Ô∏è Activity finalizada durante processamento")
                    return@launch
                }

                if (!modelLoaded || interpreter == null) {
                    Log.w(TAG, "‚ö†Ô∏è Modelo n√£o carregado")
                    processandoFace = false
                    return@launch
                }

                // ‚úÖ PROTE√á√ÉO: Recortar face com valida√ß√£o
                val faceBmp = try {
                    cropFace(bitmap, boundingBox)
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao recortar face: ${e.message}")
                    processandoFace = false
                    return@launch
                }
                
                if (faceBmp.isRecycled || faceBmp.width <= 0 || faceBmp.height <= 0) {
                    Log.e(TAG, "‚ùå Face recortada inv√°lida")
                    processandoFace = false
                    return@launch
                }

                // ‚úÖ PROTE√á√ÉO: Salvar foto da face com valida√ß√£o
                currentFaceBitmap = try {
                    val scaledBitmap = Bitmap.createScaledBitmap(faceBmp, 300, 300, true)
                    fixImageOrientationDefinitive(scaledBitmap)
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao processar foto: ${e.message}")
                    null
                }

                // ‚úÖ PROTE√á√ÉO: Redimensionar para o modelo com valida√ß√£o
                val resized = try {
                    Bitmap.createScaledBitmap(faceBmp, modelInputWidth, modelInputHeight, true)
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro ao redimensionar bitmap: ${e.message}")
                    processandoFace = false
                    return@launch
                }

                // ‚úÖ PROTE√á√ÉO CR√çTICA: Execu√ß√£o segura do TensorFlow
                var vetorFacial: FloatArray? = null
                
                try {
                    val inputTensor = convertBitmapToTensorInput(resized)
                    val output = Array(1) { FloatArray(modelOutputSize) }
                    
                    val interp = interpreter
                    if (interp != null) {
                        // ‚úÖ PROTE√á√ÉO: Executar com timeout e valida√ß√£o
                        try {
                            Log.d(TAG, "ü§ñ Executando modelo TensorFlow...")
                            interp.run(inputTensor, output)
                            Log.d(TAG, "‚úÖ Modelo executado com sucesso")
                            
                            vetorFacial = output[0]
                            
                            // ‚úÖ PROTE√á√ÉO: Validar vetor facial
                            if (vetorFacial.isNotEmpty() && vetorFacial.all { !it.isNaN() && !it.isInfinite() }) {
                                Log.d(TAG, "‚úÖ Embedding gerado: ${vetorFacial.size} dimens√µes")
                            } else {
                                Log.e(TAG, "‚ùå Vetor facial inv√°lido - valores NaN ou infinitos")
                                throw Exception("Vetor facial inv√°lido")
                            }
                        } catch (e: Exception) {
                            Log.e(TAG, "‚ùå Erro na execu√ß√£o do modelo TensorFlow: ${e.message}")
                            throw Exception("Falha na execu√ß√£o do modelo: ${e.message}")
                        }
                    } else {
                        Log.e(TAG, "‚ùå Interpreter √© nulo")
                        throw Exception("Interpreter n√£o dispon√≠vel")
                    }
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro na execu√ß√£o do TensorFlow: ${e.message}")
                    throw e
                }
                
                // ‚úÖ PROTE√á√ÉO: Verificar se o vetor facial foi gerado
                if (vetorFacial == null) {
                    Log.e(TAG, "‚ùå Vetor facial n√£o foi gerado")
                    throw Exception("Vetor facial n√£o dispon√≠vel")
                }
                
                // ‚úÖ PROTE√á√ÉO: Reconhecer face com valida√ß√£o e retry
                val funcionario = try {
                    val helper = faceRecognitionHelper
                    if (helper != null) {
                        Log.d(TAG, "üîç Iniciando reconhecimento facial...")
                        
                        // ‚úÖ SISTEMA DE RETRY: Tentar at√© 3 vezes
                        var resultado: FuncionariosEntity? = null
                        var tentativas = 0
                        val maxTentativas = 3
                        
                        while (resultado == null && tentativas < maxTentativas) {
                            try {
                                tentativas++
                                Log.d(TAG, "üîÑ Tentativa $tentativas de reconhecimento...")
                                
                                resultado = helper.recognizeFace(vetorFacial!!)
                                
                                if (resultado != null) {
                                    Log.d(TAG, "‚úÖ Reconhecimento facial bem-sucedido na tentativa $tentativas")
                                } else {
                                    Log.w(TAG, "‚ö†Ô∏è Reconhecimento retornou nulo na tentativa $tentativas")
                                }
                                
                            } catch (e: Exception) {
                                Log.e(TAG, "‚ùå Erro na tentativa $tentativas: ${e.message}")
                                if (tentativas >= 3) {
                                    throw e
                                }
                                // Aguardar um pouco antes da pr√≥xima tentativa
                                kotlinx.coroutines.delay(100)
                            }
                        }
                        
                        resultado
                    } else {
                        Log.e(TAG, "‚ùå FaceRecognitionHelper √© nulo")
                        null
                    }
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro no reconhecimento facial ap√≥s 3 tentativas", e)
                    e.printStackTrace()
                    null
                }
                    
                    if (funcionario != null) {
                        Log.d(TAG, "‚úÖ FUNCION√ÅRIO RECONHECIDO: ${funcionario.nome}")
                        
                        // ‚úÖ PROTE√á√ÉO: Registrar ponto com verifica√ß√£o de contexto
                        withContext(Dispatchers.Main) {
                            if (!isFinishing && !isDestroyed) {
                                CoroutineScope(Dispatchers.IO).launch {
                                    try {
                                        registrarPontoDireto(funcionario)
                                    } catch (e: Exception) {
                                        Log.e(TAG, "‚ùå Erro cr√≠tico no registro de ponto: ${e.message}")
                                        processandoFace = false
                                    }
                                }
                            } else {
                                Log.w(TAG, "‚ö†Ô∏è Activity finalizada antes do registro de ponto")
                                processandoFace = false
                            }
                        }
                    } else {
                        Log.w(TAG, "‚ùå Nenhum funcion√°rio reconhecido")
                        withContext(Dispatchers.Main) {
                            try {
                                if (!isFinishing && !isDestroyed) {
                                    val status = statusText
                                    status.text = "‚ùå Funcion√°rio n√£o reconhecido\nTente novamente"
                                    
                                    status.postDelayed({
                                        try {
                                            if (!isFinishing && !isDestroyed) {
                                                val statusInner = statusText
                                                statusInner.text = "üì∑ Posicione seu rosto na c√¢mera"
                                            }
                                        } catch (e: Exception) {
                                            Log.e(TAG, "‚ùå Erro no reset UI: ${e.message}")
                                        }
                                    }, 2000)
                                } else {
                                    Log.w(TAG, "‚ö†Ô∏è Activity finalizada - n√£o atualizando UI")
                                }
                            } catch (e: Exception) {
                                Log.e(TAG, "‚ùå Erro ao atualizar UI: ${e.message}")
                            }
                        }
                    }
                    
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Erro no reconhecimento: ${e.message}")
                    
                    // ‚úÖ SISTEMA DE FALLBACK: Contar erros do TensorFlow
                    tensorFlowErrorCount++
                    lastTensorFlowError = System.currentTimeMillis()
                    
                    if (tensorFlowErrorCount >= maxTensorFlowErrors) {
                        Log.w(TAG, "‚ö†Ô∏è Muitos erros do TensorFlow - ativando modo fallback")
                        tensorFlowFallbackMode = true
                        
                        // ‚úÖ FALLBACK: Usar processamento b√°sico
                        processFaceWithFallback(bitmap, boundingBox)
                        return@launch
                    }
                    
                    withContext(Dispatchers.Main) {
                        try {
                            if (!isFinishing && !isDestroyed) {
                                val status = statusText
                                status.text = "‚ùå Erro no reconhecimento\nTente novamente"
                                
                                status.postDelayed({
                                    try {
                                        if (!isFinishing && !isDestroyed) {
                                            val statusInner = statusText
                                            statusInner.text = "üì∑ Posicione seu rosto na c√¢mera"
                                        } else {
                                            Log.w(TAG, "‚ö†Ô∏è Activity finalizada - n√£o atualizando UI")
                                        }
                                    } catch (e2: Exception) {
                                        Log.e(TAG, "‚ùå Erro no reset UI: ${e2.message}")
                                    }
                                }, 2000)
                            } else {
                                Log.w(TAG, "‚ö†Ô∏è Activity finalizada - n√£o atualizando UI")
                            }
                        } catch (e2: Exception) {
                            Log.e(TAG, "‚ùå Erro ao atualizar UI: ${e2.message}")
                        }
                    }
                }
                
